{
  "models": {
    "chat": {
      "primary": "gemini-2.5-flash",
      "fallback": [
        "gemini-2.0-flash-exp"
      ],
      "description": "For general conversation and text generation",
      "capabilities": [
        "text",
        "reasoning",
        "conversation"
      ],
      "context_window": 1000000,
      "max_output_tokens": 50000
    },
    "key_phrase": {
      "primary": "gemini-2.5-flash-lite",
      "fallback": [
        "gemini-2.5-flash",
        "gemini-2.0-flash-exp"
      ],
      "description": "For fast key phrase extraction and lightweight tasks",
      "capabilities": [
        "text",
        "reasoning"
      ],
      "context_window": 1000000,
      "max_output_tokens": 8192
    },
    "vision": {
      "primary": "gemini-2.5-flash",
      "fallback": [
        "gemini-2.0-flash-exp"
      ],
      "description": "For image analysis and vision tasks",
      "capabilities": [
        "text",
        "images",
        "multimodal"
      ],
      "context_window": 1000000,
      "max_output_tokens": 50000,
      "note": "Using Flash models for vision since Pro models are over quota"
    },
    "embedding": {
      "primary": "text-embedding-004",
      "fallback": [],
      "description": "For text embeddings and semantic search",
      "capabilities": [
        "embeddings"
      ],
      "context_window": 2048
    }
  },
  "available_models": {
    "gemini-2.0-flash-exp": {
      "status": "available",
      "type": "experimental",
      "capabilities": [
        "text",
        "images",
        "multimodal"
      ],
      "context_window": 1000000,
      "generation_config": {
        "temperature": 0.7,
        "topK": 40,
        "topP": 0.95,
        "maxOutputTokens": 50000
      }
    },

    "gemini-2.5-flash": {
      "status": "available",
      "type": "stable",
      "capabilities": [
        "text",
        "images",
        "multimodal"
      ],
      "context_window": 1000000,
      "generation_config": {
        "temperature": 0.7,
        "topK": 40,
        "topP": 0.95,
        "maxOutputTokens": 50000
      }
    },

    "gemini-2.5-flash-lite": {
      "status": "available",
      "type": "stable",
      "capabilities": [
        "text",
        "reasoning"
      ],
      "context_window": 1000000,
      "generation_config": {
        "temperature": 0.3,
        "topK": 20,
        "topP": 0.9,
        "maxOutputTokens": 8192
      },
      "description": "Optimized for speed and cost-efficiency, ideal for key phrase extraction"
    },

    "text-embedding-004": {
      "status": "available",
      "type": "stable",
      "capabilities": [
        "embeddings"
      ],
      "context_window": 2048
    }
  },
  "quota_info": {
    "gemini-2.5-flash": {
      "requests_per_minute": 1500,
      "requests_per_day": 15000,
      "tokens_per_minute": 1000000,
      "tokens_per_day": 10000000
    },
    "gemini-2.5-flash-lite": {
      "requests_per_minute": 2000,
      "requests_per_day": 20000,
      "tokens_per_minute": 2000000,
      "tokens_per_day": 20000000
    },
    "gemini-2.0-flash-exp": {
      "requests_per_minute": 1000,
      "requests_per_day": 10000,
      "tokens_per_minute": 500000,
      "tokens_per_day": 5000000
    }
  },
  "validation": {
    "enforce_consistent_token_limits": true,
    "max_output_tokens": 50000,
    "warn_on_mismatch": true
  }
}