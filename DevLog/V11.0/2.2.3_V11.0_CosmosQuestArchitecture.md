# **END-STATE ARCHITECTURE: CosmosQuest V11.0 Upgrade**
## **Complete System Flow, Data Paths, and UI/UX Walkthrough**

---

## **I. SYSTEM ARCHITECTURE MAP**

### **A. File Organization & Responsibilities**

```
monorepo-root/
│
├── services/cosmos-quest-service/src/
│   ├── CosmosQuestAgent.ts           ← 🔧 MAIN LOGIC: Phases, streaming, stage directions
│   ├── CosmosQuestPromptBuilder.ts   ← 🔧 PROMPT ENGINEERING: All LLM prompts
│   └── index.ts                       ← Entry point
│
├── apps/api-gateway/src/controllers/
│   └── quest.controller.ts            ← 🌐 HTTP endpoint: receives POST /api/v1/quest/process
│
├── workers/notification-worker/src/
│   ├── index.ts                       ← Socket.IO server with /internal/quest/update
│   └── NotificationWorker.ts          ← 📡 Broadcasts to quest:{executionId} rooms
│
├── packages/tools/src/
│   ├── ai/LLMChatTool.ts              ← 🔧 ADD: modelOverride param for dynamic model selection
│   └── retrieval/HybridRetrievalTool.ts ← 🔧 ADD (Phase 4): delta caching
│
├── packages/shared-types/src/ai/
│   └── cosmos-quest.types.ts          ← 🔧 ADD: StageDirection union types
│
├── apps/web-app/src/
│   ├── app/cosmos/quest-live/page.tsx ← 🎭 ROUTE: /cosmos/quest-live
│   ├── components/cosmos/
│   │   ├── LiveQuestScene.tsx         ← 🔧 UPDATE: stage_direction reducer
│   │   ├── Graph3D.tsx                ← Renders nodes/edges (reused as-is)
│   │   ├── LookupCameraController.tsx ← 🔧 ENHANCE: smooth ease transitions
│   │   ├── NodeMesh.tsx               ← 🔧 ADD: highlight/glow props
│   │   └── EdgeMesh.tsx               ← 🔧 ADD: strength/pulse props
│   └── hooks/
│       └── useQuestConnection.ts      ← 🔧 UPDATE: handle narration_chunk, stage_direction
│
└── config/
    └── prompt_templates.yaml          ← 🔧 ADD: Cosmos-specific sections
```

---

## **II. DATA FLOW: User Request → Streaming Response**

### **Phase-by-Phase Journey**

```
┌─────────────────────────────────────────────────────────────────────┐
│ USER ACTION: Clicks "Start Quest" with question                     │
└─────────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────────┐
│ 1. FRONTEND (LiveQuestScene.tsx:32-50)                              │
│    POST /api/v1/quest/process                                       │
│    Body: { userQuestion, conversationId, questType, userId }        │
└─────────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────────┐
│ 2. API GATEWAY (quest.controller.ts:20-69)                          │
│    - Generate executionId: `cq_${Date.now()}`                       │
│    - Return { success:true, executionId, status:'processing' }      │
│    - Start background: processQuestInBackground()                   │
└─────────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────────┐
│ 3. COSMOS QUEST AGENT (CosmosQuestAgent.ts:63-127)                  │
│    processQuestWithProgressiveUpdates(input, onUpdate)              │
│                                                                      │
│    PHASE I: KEY PHRASE EXTRACTION (L71-76)                          │
│    ┌────────────────────────────────────────────────────┐          │
│    │ • CosmosQuestPromptBuilder.buildKeyPhrasePrompt()  │          │
│    │ • LLMChatTool.execute({                            │          │
│    │     modelOverride: 'gemini-2.0-flash-lite',  ← NEW │          │
│    │     enableStreaming: true,                   ← NEW │          │
│    │     onChunk: onNarrationChunk                ← NEW │          │
│    │   })                                               │          │
│    │ • onUpdate('key_phrases', { capsules: [...] })     │          │
│    └────────────────────────────────────────────────────┘          │
│                            ↓                                        │
│    PHASE II: MEMORY RETRIEVAL (L78-80)                             │
│    ┌────────────────────────────────────────────────────┐          │
│    │ • HybridRetrievalTool.execute({ keyPhrases })      │          │
│    │   → Returns ExtendedAugmentedMemoryContext         │          │
│    └────────────────────────────────────────────────────┘          │
│                            ↓                                        │
│    PHASE III: VISUALIZATION (L82-95) — WILL BE REPLACED            │
│    ┌────────────────────────────────────────────────────┐          │
│    │ [Current: hardcoded stage1/2/3 split]              │          │
│    │ [Future: emit dws_ready with small graph]          │          │
│    └────────────────────────────────────────────────────┘          │
│                            ↓                                        │
│    PHASE IV: FINAL RESPONSE & STAGE DIRECTIONS (L97-106)           │
│    ┌────────────────────────────────────────────────────┐          │
│    │ • CosmosQuestPromptBuilder.buildFinalPrompt()      │          │
│    │ • LLMChatTool.execute({                            │          │
│    │     modelOverride: 'gemini-2.0-flash',             │          │
│    │     enableStreaming: true,                   ← NEW │          │
│    │     onChunk: onNarrationChunk                ← NEW │          │
│    │   })                                               │          │
│    │ • Parse JSON response for:                         │          │
│    │   - direct_response_text (Part A)                  │          │
│    │   - stage_directions: [...]     (Part B)     ← NEW │          │
│    │   - reflective_question                            │          │
│    │ • onUpdate('narration_chunk', chunk)         ← NEW │          │
│    │ • onUpdate('stage_direction', {...})         ← NEW │          │
│    └────────────────────────────────────────────────────┘          │
└─────────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────────┐
│ 4. QUEST CONTROLLER → NOTIFICATION WORKER                           │
│    quest.controller.ts:sendQuestUpdate() (L97-118)                  │
│    ┌────────────────────────────────────────────────────┐          │
│    │ HTTP POST /internal/quest/update                   │          │
│    │ Body: { executionId, data: { type, ...data } }    │          │
│    └────────────────────────────────────────────────────┘          │
└─────────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────────┐
│ 5. NOTIFICATION WORKER (NotificationWorker.ts:220-227)              │
│    this.io.to(`quest:${executionId}`).emit('quest:update', {...})   │
└─────────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────────┐
│ 6. FRONTEND (useQuestConnection.ts:38-72)                           │
│    socket.on('quest:update', (data) => { ... })                     │
│    ┌────────────────────────────────────────────────────┐          │
│    │ switch (data.type) {                               │          │
│    │   case 'key_phrases': setState(...)                │          │
│    │   case 'narration_chunk': appendText(...)    ← NEW │          │
│    │   case 'stage_direction': dispatch(...)      ← NEW │          │
│    │   case 'final_response': ...                       │          │
│    │ }                                                  │          │
│    └────────────────────────────────────────────────────┘          │
└─────────────────────────────────────────────────────────────────────┘
                            ↓
┌─────────────────────────────────────────────────────────────────────┐
│ 7. FRONTEND RENDERING (LiveQuestScene.tsx)                          │
│    - Graph3D: nodes + edges                                         │
│    - Camera: LookupCameraController listens to                      │
│      'camera-focus-request' events                                  │
│    - Highlights: NodeMesh/EdgeMesh props update                     │
└─────────────────────────────────────────────────────────────────────┘
```

---

## **III. PROMPT ENGINEERING: Where & How**

### **File: `services/cosmos-quest-service/src/CosmosQuestPromptBuilder.ts`**

#### **Current Methods:**
1. `buildKeyPhraseExtractionPrompt(input)` (L50-92)
   - **System prompt** (L148-182): Hardcoded instructions for extracting 3-7 key phrases
   - **User prompt** (L187-197): Simple template with user question

2. `buildFinalResponsePrompt(input)` (L97-143)
   - **System prompt** (L202-253): Hardcoded guidelines for response + walkthrough
   - **User prompt** (L258-276): Includes augmented memory context + visualization data

#### **🔧 CHANGES NEEDED:**

##### **A. Integrate with Shared Prompt Infrastructure**

**Current State:** Prompts are hardcoded strings in methods.

**End State:** Load from `config/prompt_templates.yaml` via `ConfigService.getTemplate()`.

```typescript
// L98-100 in PromptBuilder.ts shows the pattern:
const coreIdentityTpl = this.configService.getTemplate('core_identity_section');
const operationalConfigTpl = this.configService.getTemplate('operational_config_section');
```

**Action:**
1. **Add to `config/prompt_templates.yaml`:**
```yaml
cosmos_quest_key_phrase_system:
  template: |
    === COSMOS QUEST AGENT - KEY PHRASE EXTRACTION ===
    
    You are a specialized AI assistant for CosmosQuestAgent...
    [rest of current L152-182 content]

cosmos_quest_final_response_system:
  template: |
    === COSMOS QUEST AGENT - FINAL RESPONSE GENERATION ===
    
    You are a specialized AI assistant for CosmosQuestAgent...
    
    **CRITICAL: Stage Directions Output Format**
    In addition to response_text and reflective_question, you must include:
    
    "stage_directions": [
      {
        "action": "camera_focus",
        "entity_id": "uuid-of-entity",
        "offset": [10, 5, 10],
        "ease_ms": 800
      },
      {
        "action": "highlight_nodes",
        "ids": ["uuid1", "uuid2"],
        "mode": "spotlight",
        "dim_others": true,
        "ease_ms": 600
      },
      {
        "action": "reveal_entities",
        "ids": ["uuid3"],
        "layout_hint": "near_uuid1",
        "ease_ms": 1000
      },
      {
        "action": "environment",
        "starfield": "dim",
        "vignette_opacity": 0.3,
        "fade_ms": 500
      }
    ]
    
    Available actions: camera_focus, highlight_nodes, highlight_edges, reveal_entities, environment, show_details
    
    Emit stage_directions in narrative order, coordinated with your response_text beats.
```

2. **Update `CosmosQuestPromptBuilder.buildKeyPhraseSystemPrompt()` (L148):**
```typescript
private buildKeyPhraseSystemPrompt(...): string {
  const basePrompt = this.configService.getTemplate('cosmos_quest_key_phrase_system');
  const essentialUserContext = this.formatEssentialUserContext(user);
  return `${basePrompt}\n${essentialUserContext || ''}`;
}
```

3. **Update `CosmosQuestPromptBuilder.buildFinalResponseSystemPrompt()` (L202):**
```typescript
private buildFinalResponseSystemPrompt(user: any): string {
  const basePrompt = this.configService.getTemplate('cosmos_quest_final_response_system');
  const essentialUserContext = this.formatEssentialUserContext(user);
  return `${basePrompt}\n${essentialUserContext || ''}`;
}
```

##### **B. Add Streaming Narration Instructions**

Currently `buildFinalResponsePrompt` doesn't mention streaming. **Add to user prompt**:

```typescript
// L258-276
private buildFinalResponseUserPrompt(...): string {
  return `=== FINAL RESPONSE GENERATION ===

User: ${userName}
Original Question: "${userQuestion}"

${memoryContext}
${visualizationContext}

**STREAMING INSTRUCTIONS:**
Your response_text will be streamed to the user in real-time. Write naturally; 
each sentence will appear as you generate it. Coordinate your stage_directions 
with narrative beats so the camera and highlights move as you mention entities.

Example coordination:
- Sentence: "Let's start with your skating memory..." 
  → stage_direction: { action: "camera_focus", entity_id: "skating_memoryunit_id" }
- Sentence: "Notice the connection to therapy sessions..."
  → stage_direction: { action: "highlight_edges", pairs: [["skating_id", "therapy_id"]] }

Please generate a thoughtful response, stage_directions array, and reflective question.`;
}
```

---

## **IV. UI/UX WALKTHROUGH: User's Complete Journey**

### **Timeline: What User Sees Second-by-Second**

#### **T=0s: User Action**
- **UI:** LiveQuestScene (L276-296)
- Input field: "What do you know about my skating experience?"
- Click **"Start Quest"**
- **Network:** POST /api/v1/quest/process → returns `{executionId: "cq_1704567890123"}`
- **Hook:** `useQuestConnection.joinQuest(executionId)` → Socket.IO emits `quest:join`

---

#### **T+0.3s: Loading State**
- **UI:** LiveQuestScene (L177-202)
- **Display:**
  ```
  ┌───────────────────────────────┐
  │    [spinner animation]        │
  │   Processing Quest            │
  │  Exploring your memories...   │
  └───────────────────────────────┘
  ```
- **Backend:** CosmosQuestAgent starts Phase I

---

#### **T+0.6s: Key Phrases Arrive**
- **Socket.IO:** `quest:update` with `type: 'key_phrases'`
- **Payload:**
  ```json
  {
    "type": "key_phrases",
    "capsules": [
      { "phrase": "skating", "confidence_score": 0.95, "color": "#ff6b6b" },
      { "phrase": "ice skating", "confidence_score": 0.9, "color": "#4ecdc4" },
      { "phrase": "winter sports", "confidence_score": 0.85, "color": "#45b7d1" }
    ]
  }
  ```
- **UI:** LiveQuestScene (L299-314) — Top-left corner shows chips:
  ```
  ┌─────────────────────────────────┐
  │ [skating] [ice skating] [winter]│
  └─────────────────────────────────┘
  ```

---

#### **T+0.8s to T+3.5s: NARRATION STREAMING BEGINS** ✨ **[NEW]**
- **Socket.IO:** Continuous `quest:update` with `type: 'narration_chunk'`
- **Payload stream:**
  ```json
  { "type": "narration_chunk", "content": "Let me orient" }
  { "type": "narration_chunk", "content": " to your cosmos" }
  { "type": "narration_chunk", "content": "... I'll begin by" }
  { "type": "narration_chunk", "content": " grounding in your" }
  { "type": "narration_chunk", "content": " recent work." }
  ```
- **UI:** LiveQuestScene bottom-center (new component):
  ```
  ┌──────────────────────────────────────────┐
  │  Let me orient to your cosmos... I'll    │
  │  begin by grounding in your recent work. │
  └──────────────────────────────────────────┘
  ```
- **UX:** Text appears smoothly, character by character or word by word

---

#### **T+1.5s: Visualization Ready**
- **Socket.IO:** `quest:update` with `type: 'visualization_stage_1'`
- **Payload:**
  ```json
  {
    "type": "visualization_stage_1",
    "entities": [
      {
        "entityId": "uuid-skating-memory",
        "entityType": "MemoryUnit",
        "position": [10.5, 2.3, -5.7],
        "starTexture": "bright_star",
        "title": "First skating lesson",
        "relevanceScore": 0.92
      },
      ...
    ]
  }
  ```
- **UI:** Graph3D (L317-330)
  - Nodes appear as **bright stars** (NodeMesh, isSearchResult=true, L104-108)
  - Position at scaled coordinates
  - Camera at `[center.x+200, center.y+200, center.z-150]`

---

#### **T+2.8s: Stage Direction — CAMERA FOCUS** ✨ **[NEW]**
- **Socket.IO:** `quest:update` with `type: 'stage_direction'`
- **Payload:**
  ```json
  {
    "type": "stage_direction",
    "action": "camera_focus",
    "entity_id": "uuid-skating-memory",
    "offset": [10, 5, 10],
    "ease_ms": 800
  }
  ```
- **Hook:** useQuestConnection reducer (new case):
  ```typescript
  case 'stage_direction':
    if (data.action === 'camera_focus') {
      const entity = nodes.find(n => n.id === data.entity_id);
      if (entity) {
        const event = new CustomEvent('camera-focus-request', {
          detail: { position: { x: entity.x, y: entity.y, z: entity.z }, entity }
        });
        window.dispatchEvent(event);
      }
    }
    break;
  ```
- **Component:** LookupCameraController (L40-67)
  - Listens to `camera-focus-request`
  - Smoothly tweens camera to new target
  - **UX:** Camera glides to the "First skating lesson" star over 800ms

---

#### **T+3.0s: Stage Direction — HIGHLIGHT NODES** ✨ **[NEW]**
- **Payload:**
  ```json
  {
    "type": "stage_direction",
    "action": "highlight_nodes",
    "ids": ["uuid-skating-memory"],
    "mode": "spotlight",
    "dim_others": true,
    "ease_ms": 600
  }
  ```
- **Hook:** Update scene state: `highlightedNodes: ["uuid-skating-memory"], dimOthers: true`
- **Component:** NodeMesh (enhanced, L28-29):
  ```typescript
  interface NodeMeshProps {
    ...
    isHighlighted?: boolean;  ← Pass from Graph3D
    dimFactor?: number;       ← NEW: 0.3 when dimOthers=true
  }
  ```
- **Render logic (L142-155 enhanced):**
  ```typescript
  const baseIntensity = isHighlighted ? 2.0 : (dimFactor || 1.0);
  const emissiveIntensity = isHighlighted ? 0.8 : 0.2;
  ```
- **UX:** "First skating lesson" star **glows brightly**; other stars fade to 30% brightness

---

#### **T+3.5s: Narration Continues + Edge Highlight**
- **Narration chunk:** `"Notice the path from skating to therapy..."`
- **Stage direction:**
  ```json
  {
    "type": "stage_direction",
    "action": "highlight_edges",
    "pairs": [["uuid-skating-memory", "uuid-therapy-memory"]],
    "strength": 1.0,
    "ease_ms": 500
  }
  ```
- **Component:** EdgeMesh (enhanced):
  ```typescript
  interface EdgeMeshProps {
    ...
    isHighlighted?: boolean;  ← NEW
    strength?: number;        ← NEW: 1.0 = full glow
  }
  ```
- **Render (enhanced):**
  ```typescript
  const lineWidth = isHighlighted ? edgeWidth * 2 : edgeWidth;
  const opacity = isHighlighted ? 1.0 : edgeOpacity;
  material.emissive = isHighlighted ? new THREE.Color(0x4a90e2) : new THREE.Color(0x000000);
  material.emissiveIntensity = isHighlighted ? strength * 0.5 : 0;
  ```
- **UX:** The edge between "skating" and "therapy" **pulses with blue glow**

---

#### **T+4.0s: Environment Change — Starfield Dim**
- **Payload:**
  ```json
  {
    "type": "stage_direction",
    "action": "environment",
    "starfield": "dim",
    "vignette_opacity": 0.3,
    "fade_ms": 500
  }
  ```
- **Component:** Graph3D (enhanced L277-286):
  ```typescript
  <NASAStarfieldBackground 
    resolution="4k" 
    opacity={starfieldOpacity}  ← NEW: controlled by state
  />
  <StarfieldBackground 
    opacity={proceduralStarOpacity}  ← NEW
  />
  ```
- **Hook:** `setStarfieldOpacity(0.3)` with smooth transition
- **UX:** Background stars **fade**, focusing attention on highlighted nodes

---

#### **T+5.2s: Reveal New Entity**
- **Narration:** `"Here's an interesting connection..."`
- **Payload:**
  ```json
  {
    "type": "stage_direction",
    "action": "reveal_entities",
    "ids": ["uuid-resilience-concept"],
    "layout_hint": "near_uuid-therapy-memory",
    "ease_ms": 1000
  }
  ```
- **Hook:** 
  ```typescript
  case 'reveal_entities':
    // Add entity to nodes array if not already visible
    const newNode = allEntities.find(e => e.id === data.ids[0]);
    if (newNode && !nodes.find(n => n.id === newNode.id)) {
      setNodes([...nodes, newNode]);
      // Trigger fade-in animation
      setRevealingNodeId(newNode.id);
    }
    break;
  ```
- **Component:** NodeMesh (L201-210, enhanced with opacity tween):
  ```typescript
  const [opacity, setOpacity] = useState(isRevealing ? 0 : 1);
  
  useEffect(() => {
    if (isRevealing) {
      // Tween opacity 0 → 1 over ease_ms
      const start = performance.now();
      const animate = (now: number) => {
        const elapsed = now - start;
        const progress = Math.min(elapsed / ease_ms, 1);
        setOpacity(progress);
        if (progress < 1) requestAnimationFrame(animate);
      };
      requestAnimationFrame(animate);
    }
  }, [isRevealing, ease_ms]);
  
  <meshStandardMaterial opacity={opacity} transparent ... />
  ```
- **UX:** "Resilience" concept star **fades in** smoothly from invisible to bright

---

#### **T+6.0s: Final Narration + Reflective Question**
- **Narration:** `"Take a moment to reflect..."`
- **Socket.IO:** `quest:update` with `type: 'final_response'`
- **Payload:**
  ```json
  {
    "type": "final_response",
    "reflective_question": "What patterns do you notice in your journey?"
  }
  ```
- **UI:** Bottom-center panel (L366-372):
  ```
  ┌─────────────────────────────────────────────┐
  │  What patterns do you notice in your        │
  │  journey?                                   │
  │                                             │
  │  [Pause] [Skip to Summary] [Ask Question]   │
  └─────────────────────────────────────────────┘
  ```
- **UX:** Narration stops; user can interact or let tour continue

---

## **V. CODE CHANGES SUMMARY BY FILE**

### **Backend Changes**

| File | Lines | What Changes | Why |
|------|-------|--------------|-----|
| `packages/tools/src/ai/LLMChatTool.ts` | 44-68 | Add `modelOverride?: string` to `LLMChatInputPayload` | Allow CosmosQuestAgent to request flash-lite vs flash/pro dynamically |
| | 137-142 | Use `input.payload.modelOverride \|\| getModelForUseCase('chat')` | Apply override if provided |
| `packages/shared-types/src/ai/cosmos-quest.types.ts` | NEW | Define `StageDirection` union type (camera_focus, highlight_nodes, highlight_edges, reveal_entities, environment, show_details) | Shared contract between agent and frontend |
| `services/cosmos-quest-service/src/CosmosQuestPromptBuilder.ts` | 148, 202 | Load prompts from `ConfigService.getTemplate()` instead of hardcoded strings | Share infrastructure with DialogueAgent; enable caching |
| | 258-276 | Add streaming coordination instructions to user prompt | Guide LLM to emit stage directions aligned with narration beats |
| `services/cosmos-quest-service/src/CosmosQuestAgent.ts` | 71-76 | Add `modelOverride: 'gemini-2.0-flash-lite', enableStreaming: true, onChunk: onNarrationChunk` to key phrase LLM call | Fast extraction + stream narration immediately |
| | 97-106 | Add `enableStreaming: true, onChunk: onNarrationChunk` to final response LLM call | Stream Part A (direct response) and Part B (stage directions) |
| | NEW method | `parseStageDirections(llmResult): StageDirection[]` | Extract stage_directions array from LLM JSON response |
| | 102-106 | Emit `onUpdate('narration_chunk', chunk)` and `onUpdate('stage_direction', {...})` | Push streaming text and stage commands to frontend |
| `apps/api-gateway/src/controllers/quest.controller.ts` | 97-118 | Forward `narration_chunk` and `stage_direction` events to NotificationWorker | Relay agent updates to Socket.IO |
| `config/prompt_templates.yaml` | NEW | Add `cosmos_quest_key_phrase_system`, `cosmos_quest_final_response_system` sections | Centralize prompt content; enable caching |

---

### **Frontend Changes**

| File | Lines | What Changes | Why |
|------|-------|--------------|-----|
| `apps/web-app/src/hooks/useQuestConnection.ts` | 38-72 | Add `case 'narration_chunk'`: append to `accumulatedNarration` | Accumulate streaming text chunks |
| | | Add `case 'stage_direction'`: dispatch actions based on `data.action` | Execute camera focus, highlights, reveals, env changes |
| `apps/web-app/src/components/cosmos/LiveQuestScene.tsx` | NEW | Add narration display component (bottom-center, live-updating text) | Show streaming response to user |
| | 111-135 | Enhance `focusCameraOnEntity` to accept `ease_ms` param | Support smooth transitions from stage directions |
| | NEW | Add reducer logic for `highlight_nodes`, `highlight_edges`, `reveal_entities`, `environment` | Translate stage directions into scene state updates |
| `apps/web-app/src/components/cosmos/Graph3D.tsx` | 39-56 | Add `highlightedNodeIds?: string[], dimOthers?: boolean, starfieldOpacity?: number` props | Pass highlight/env state to child components |
| | 277-286 | Control `NASAStarfieldBackground` opacity via prop | Dim/brighten background on stage direction |
| `apps/web-app/src/components/cosmos/NodeMesh.tsx` | 23-30 | Add `isHighlighted?: boolean, dimFactor?: number, isRevealing?: boolean, ease_ms?: number` props | Support dynamic highlights and fade-in animations |
| | 142-155 | Adjust `emissiveIntensity`, `opacity` based on highlight state | Glow bright when highlighted; fade when dimOthers=true |
| | NEW | Add opacity tween for `isRevealing` entities | Smooth fade-in over `ease_ms` |
| `apps/web-app/src/components/cosmos/EdgeMesh.tsx` | NEW | Add `isHighlighted?: boolean, strength?: number` props | Support edge glow/pulse |
| | NEW | Adjust `lineWidth`, `opacity`, `emissive` based on highlight state | Pulse edges when agent references them |
| `apps/web-app/src/components/cosmos/LookupCameraController.tsx` | 40-67 | Enhance `camera-focus-request` handler to accept `ease_ms` and tween camera position | Smooth camera movement instead of instant snap |

---

## **VI. SUMMARY: The Vision Realized**

### **What Users Experience:**
1. **Instant Feedback**: Narration starts within 600ms (flash-lite key phrases + streaming).
2. **Cinematic Control**: Camera glides, stars glow, edges pulse—all choreographed by the agent.
3. **Fluid Narrative**: No rigid 4-stage PPT; the agent tells a story and the scene follows.
4. **Interruptible**: Pause, skip, or ask a new question mid-tour (Phase 5, deferred).

### **What Engineers Build:**
- **Backend**: Dynamic model selection, streaming LLM calls, stage-direction DSL, prompt caching.
- **Frontend**: Reducer for stage directions, enhanced Node/EdgeMesh components, camera tweening.
- **Infra**: Shared prompt templates, HRT delta caching, Redis retry resilience.

### **Alignment with Monorepo Principles:**
- ✅ Modularity: `CosmosQuestAgent` is a standalone service; `LLMChatTool` is reusable.
- ✅ Typed: `StageDirection` types in `shared-types`; no magic strings.
- ✅ Config-driven: Prompts in YAML; models selected via `ConfigService`.
- ✅ Tested: Each phase (streaming, model override, stage directions) is unit-testable.

---

**We are on the exact same page.** This is the complete end-state architecture grounded in your current codebase structure. Ready to start implementation?