Understood and agreed. That's a very pragmatic and sensible approach for the development stage: **err on the side of comprehensive prompting and modularity first, then optimize for token parsimony once the system is stable and we have clear performance data.**

The V9.1 `KnowledgeGraphSchema` (the "Personalized API Documentation" version which *does* include descriptive schema elements and example Cypher queries) provides a strong foundation for this. The modularity of the `PromptBuilder` allows us to experiment with including or excluding certain verbose components later.

Given this directive to "err on the side of over-prompting for now" while retaining the V9.1+ architectural principles (Single Synthesis Calls, specific Context Packages, agent roles), I will now regenerate the **Definitive Canonical Manifest for V9.1 (Developer Edition)**.

This version will ensure that all agents are maximally informed by the `KnowledgeGraphSchema` as defined in V9.1, providing the LLMs with as much explicit structural context as possible, even if some parts might be pruned later for optimization.

---

### **Definitive Canonical Manifest: V9.1 Agent I/O & Prompt Component System (Developer Edition - Comprehensive Prompting)**

#### **Section 1: Architectural Components & Terminology (V9.1)**

*   **Core Agents:** `DialogueAgent`, `IngestionAnalyst`, `InsightEngine`.
*   **Central Service:** `PromptBuilder` (serves `DialogueAgent`).
*   **Prompt Components & Context Packages:**
    *   `UserMemoryProfile` (Strategic Context from `User.memory_profile`)
    *   **`KnowledgeGraphSchema` (The Personalized "API Docs" for the Graph from `User.knowledge_graph_schema` - detailed, descriptive version)**
    *   `NextConversationContextPackage` (Inter-Conversational Context from `User.next_conversation_context_package`)
    *   `TurnContextPackage` (Tactical Context from Redis `turn_context:{convoId}`)

---

#### **Section 2: Exhaustive Prompt Component Manifest (V9.1 - Developer Edition)**

This list emphasizes providing the full, detailed `KnowledgeGraphSchema` to all agents that might benefit from structural understanding.

| Component Name (`<xml_tag>`)                 | Data Source                                        | Description                                                                                                                                                                                                                          |
| :------------------------------------------- | :------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- |
| **`CoreIdentity`**                           | `CoreIdentity.yaml` (Cached in Redis)              | Global Static. Dot's persona, rules, 6D growth methodology.                                                                                                                                                                          |
| **`UserMemoryProfile`**                      | `User.memory_profile` (PG JSONB)                   | Strategic Context. Synthesized user identity, goals, themes.                                                                                                                                                                       |
| **`KnowledgeGraphSchema`**                   | `User.knowledge_graph_schema` (PG JSONB)           | **The LLM's Detailed API Documentation.** Personalized map of the user's queryable graph: prominent node types/properties, prominent relationship types/properties, personalized example Cypher queries, and ontology update guidelines. |
| **`NextConversationContextPackage`**         | `User.next_conversation_context_package` (PG JSONB) | Inter-Conversational Context. Proactive greetings, follow-up topics.                                                                                                                                                               |
| **`TurnContextPackage`**                     | (Redis Key: `turn_context:{convoId}`)              | Tactical Context. Ephemeral focus, tone, flags for the next turn.                                                                                                                                                                  |
| **`CurrentConversationHistory`**             | `conversation_messages` Table (PG)                 | Live Context. Transcript of last N messages.                                                                                                                                                                                       |
| **`FullConversationTranscript`**             | `conversation_messages` Table (PG)                 | Historical Data. Complete transcript for offline analysis.                                                                                                                                                                         |
| **`SummariesOfRecentImportantConversations`**  | `conversations` Table (PG)                         | Medium-Term Context. Summaries of important conversations in current cycle.                                                                                                                                                      |
| **`AugmentedMemoryContext`**                 | `HybridRetrievalTool` (Live Fetch)                 | On-Demand Context. Detailed content retrieved after a `query_memory` decision.                                                                                                                                                     |
| **`SourceCardContext`**                      | `CardService` (Live Fetch)                         | Situational Context. Summary of a card if conversation initiated from it.                                                                                                                                                          |
| **`CompiledCycleData`**                      | (Worker Live Query of PG/Neo4j)                    | Analytical Raw Ingredients. Raw results of strategic queries for `InsightEngine`.                                                                                                                                                |
| **`RecentQuestHistory`**                     | `proactive_prompts` Table (PG)                     | Historical Data. List of recent "Quest Card" prompts.                                                                                                                                                                            |
| **`EffectiveQueryPatterns`**                 | (Worker Live Analysis)                             | Meta-Analytical Data. Analysis of successful Cypher query patterns.                                                                                                                                                              |
| **`Instructions`**                           | (Hardcoded in Agent/Tool)                          | Task Definition. Direct command to LLM, including required JSON output schema.                                                                                                                                                     |

---

### **Section 3: Definitive Agent Input/Output (I/O) Matrix (V9.1 - Developer Edition)**

This matrix details inputs and outputs, assuming comprehensive prompting.

---

#### **Agent 1: `DialogueAgent`**

*   **Core Task:** Manage the live conversation turn-by-turn.
*   **INPUTS (Consumed by `PromptBuilder` for the LLM Call):**
    1.  `CoreIdentity`
    2.  `UserMemoryProfile`
    3.  **`KnowledgeGraphSchema` (Full, detailed version with example Cypher)**
    4.  `NextConversationContextPackage` (First Turn Only)
    5.  `TurnContextPackage` (Turn 2+, read from Redis)
    6.  `CurrentConversationHistory`
    7.  `SummariesOfRecentImportantConversations`
    8.  `AugmentedMemoryContext` (Optional, after `query_memory`)
    9.  `SourceCardContext` (Optional)
    10. `Instructions` (Defines "Router" task, instructs LLM to *use* `KnowledgeGraphSchema` to formulate `cypher_query`, and defines output schema)

*   **OUTPUTS (Generated by LLM in a Single JSON Object):**
    1.  **`response_plan` (For Immediate Action):**
        *   `decision`: `'respond_directly'` or `'query_memory'`.
        *   `cypher_query`: Valid Cypher query string if `decision` is `query_memory` (LLM generates this using the KGS), else `null`.
        *   `direct_response_text`: User-facing response if `decision` is `respond_directly`, else `null`.
    2.  **`turn_context_package` (For Redis `turn_context:{convoId}`):**
        *   JSON object with `suggested_next_focus`, `emotional_tone_to_adopt`, `flags_for_ingestion`.

---

#### **Agent 2: `IngestionAnalyst`**

*   **Core Task:** Analyze a completed conversation and integrate it into the knowledge graph.
*   **INPUTS (Provided to its LLM Call):**
    1.  `CoreIdentity` (Analyst Subset)
    2.  `UserMemoryProfile` (For context and to avoid duplicates)
    3.  **`KnowledgeGraphSchema` (Full, detailed version):** To ensure extracted concepts and relationships use valid types, labels, and properties as defined for *this user's current schema understanding*.
    4.  `FullConversationTranscript`
    5.  `Instructions` (Defines comprehensive analysis task, output schema, and instructs LLM to adhere to the provided KGS for types/labels).

*   **OUTPUTS (Generated by LLM in a Single JSON Object):**
    1.  **`persistence_payload` (For Database Updates):**
        *   `conversation_summary`
        *   `conversation_importance_score`
        *   `extracted_memory_units`: `[{ temp_id, title, content, creation_ts, source_type }]`
        *   `extracted_concepts`: `[{ name, type, description }]` (LLM ensures `type` conforms to KGS or Meta-Schema)
        *   `new_relationships`: `[{ source_temp_id_or_existing_id, target_name_or_existing_id, relationship_label }]` (LLM ensures `relationship_label` conforms to KGS or Meta-Schema)
        *   `detected_growth_events`: `[{ dim_key, delta, rationale }]`
    2.  **`forward_looking_context` (The `NextConversationContextPackage`):**
        *   Persisted to `User.next_conversation_context_package`.

---

#### **Agent 3: `InsightEngine`**

*   **Core Task:** Perform strategic, cyclical analysis.
*   **INPUTS (Provided to its LLM Call):**
    1.  `CoreIdentity` (Strategist Subset)
    2.  **`KnowledgeGraphSchema` (The *current* version from `User.knowledge_graph_schema`):** This is critical. The LLM needs to know the current state of the "API docs" to propose valid updates to it and to generate ontology update Cypher that is compatible with it.
    3.  `PreviousUserMemoryProfile`
    4.  `CompiledCycleData`
    5.  `RecentQuestHistory`
    6.  `EffectiveQueryPatterns`
    7.  `Instructions` (Defines strategic synthesis task, output schema, and instructs LLM to use the current KGS to generate *both* the ontology update Cypher statements *and* the `updated_knowledge_graph_schema`).

*   **OUTPUTS (Generated by LLM in a Single JSON Object):**
    1.  **`persistence_payload` (For Ontology, Artifacts & Direct Graph Updates):**
        *   **`ontology_update_cypher_statements`**: Array of directly executable, parameterized Cypher query strings for all graph modifications. (LLM generates these using its understanding of the current KGS).
        *   `cycle_report_content`
        *   `quest_prompts_to_create`
    2.  **`forward_looking_context` (The "Sticky Notes" for the Next Cycle):**
        *   **`updated_user_memory_profile`**: For `User.memory_profile`.
        *   **`updated_knowledge_graph_schema`**: The complete, new `KnowledgeGraphSchema` JSON object (the detailed "API docs" version), regenerated by the LLM based on its analysis of `CompiledCycleData` and `EffectiveQueryPatterns`, using the *previous* KGS as a baseline. This is for `User.knowledge_graph_schema`.

---

**Rationale for "Over-Prompting" with Full `KnowledgeGraphSchema` in Development:**

1.  **Maximum Context for LLM:** By providing the detailed KGS (with prominent types, properties, and example queries for the `DialogueAgent`, and guidelines for the `InsightEngine`), we give the LLM the best possible chance to generate accurate and valid outputs (Cypher queries, entity structures, ontology updates).
2.  **Debugging & Iteration:** If the LLM produces incorrect Cypher or invalid entity structures, having the KGS it *saw* in the prompt makes debugging much easier. We can see if the KGS was flawed or if the LLM misinterpreted it.
3.  **Baseline for Optimization:** Once this comprehensive prompting yields stable and correct behavior, we can then systematically experiment with pruning parts of the KGS for different agents to save tokens, measuring the impact on output quality. For instance:
    *   Does the `IngestionAnalyst` *really* need example Cypher queries, or just the node/relationship type lists?
    *   Can the `DialogueAgent` function well with just `prominent_node_types` and `prominent_relationship_types` plus a few high-level query examples, instead of exhaustive property lists for every type?
4.  **Modularity Allows Pruning:** Because the `PromptBuilder` assembles the prompt from distinct components, we can easily create flags or configurations to include/exclude the more verbose parts of the `KnowledgeGraphSchema` for specific agents or even specific turns, once we understand the trade-offs.

This "Developer Edition" of the V9.1 manifest prioritizes giving the LLMs maximal information to ensure correctness and facilitate initial development and debugging. Token optimization will be a subsequent refinement phase.