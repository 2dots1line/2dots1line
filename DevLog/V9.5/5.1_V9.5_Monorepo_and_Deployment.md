### **`5.1_V9.5_Monorepo_and_Deployment.md`**

---

# **V9.5 Definitive Guide: Monorepo Structure & Deployment Strategy**

**Document Version:** 9.5
**Purpose:** To provide the single, canonical source of truth for the 2dots1line monorepo file structure and the corresponding Docker-based development and deployment strategy.

## **1. Core Principles of the V9.5 Monorepo**

The V9.5 monorepo is organized around clarity, separation of concerns, and efficient build orchestration using `pnpm` workspaces and `Turborepo`.

1.  **Logical Directory Grouping:**
    *   `apps/`: User-facing applications and the API Gateway.
    *   `services/`: Real-time backend services that handle synchronous requests.
    *   `workers/`: Asynchronous background job processors.
    *   `packages/`: Shared libraries, specialized tools, and database clients.
    *   `config/`: Centralized, non-code configuration files.
2.  **Service-Oriented Backend:** The monolithic `cognitive-hub` is fully dissolved into specialized, independently deployable services and workers.
3.  **Unified Docker Strategy:** A single root `Dockerfile` is used to build all Node.js services and workers, parameterized by build arguments. This simplifies build orchestration and ensures consistency.

---

## **2. Definitive V9.5 Monorepo File Structure**

This is the target file-level structure. There should be no ambiguity.

```
/2dots1line/
├── .dockerignore
├── .eslintrc.js
├── .gitignore
├── .prettierrc.js
├── Dockerfile                    # V9.5: Single, root Dockerfile for all Node.js services/workers
├── docker-compose.yml            # V9.5: Orchestrates all services, workers, and databases for local dev
├── package.json
├── pnpm-lock.yaml
├── pnpm-workspace.yaml
├── README.md
├── tsconfig.base.json
└── turbo.json
│
├── apps/
│   ├── api-gateway/              # Lean Express.js gateway
│   │   ├── src/
│   │   │   ├── controllers/      # auth.controller, card.controller, conversation.controller, etc.
│   │   │   ├── middleware/       # auth.middleware, upload.middleware
│   │   │   └── routes/
│   │   │       └── v1/           # auth.routes, card.routes, conversation.routes, etc.
│   │   ├── package.json
│   │   └── tsconfig.json
│   └── web-app/                  # Next.js frontend
│       └── ... (Internal structure remains a frontend concern)
│
├── services/                     # Real-time backend services
│   ├── dialogue-service/
│   │   ├── src/
│   │   │   ├── DialogueAgent.ts
│   │   │   ├── OrbStateManager.ts
│   │   │   ├── PromptBuilder.ts
│   │   │   └── index.ts          # Service entry point
│   │   └── package.json
│   └── card-service/
│       ├── src/
│       │   ├── CardService.ts
│       │   ├── CardFactory.ts    # Co-located as it's tightly coupled
│       │   └── index.ts
│       └── package.json
│
├── workers/                      # Asynchronous background workers
│   ├── ingestion-worker/
│   │   ├── src/
│   │   │   ├── IngestionAnalyst.ts
│   │   │   └── index.ts          # Worker entry point, connects to BullMQ
│   │   └── package.json
│   ├── insight-worker/
│   │   ├── src/
│   │   │   ├── InsightEngine.ts
│   │   │   └── index.ts
│   │   └── package.json
│   ├── card-worker/              # NEW
│   │   ├── src/
│   │   │   ├── CardWorker.ts
│   │   │   └── index.ts
│   │   └── package.json
│   └── graph-projection-worker/  # NEW
│       ├── src/
│       │   ├── GraphProjectionWorker.ts
│       │   └── index.ts
│       └── package.json
│
├── packages/                     # Shared libraries and tools
│   ├── database/
│   │   ├── prisma/
│   │   │   └── schema.prisma     # The V9.5 schema
│   │   └── src/
│   │       ├── repositories/     # All PG repositories
│   │       └── neo4j/
│   │           └── queries/
│   │               └── insight-queries.ts # The V9.5 InsightQueryLibrary
│   ├── shared-types/
│   │   └── ...
│   ├── tool-registry/            # Re-instated for V9.2+ architecture
│   │   └── src/
│   │       └── ToolRegistry.ts
│   └── tools/
│       ├── ai/                   # Atomic AI tools (LLMChatTool, etc.)
│       ├── data/                 # Atomic data processing tools (AudioTranscribe, etc.)
│       ├── retrieval/            # Specialized HybridRetrievalTool
│       └── composite/            # Composite tools (HolisticAnalysisTool, etc.)
│
├── config/                       # Centralized configuration
│   ├── CoreIdentity.yaml
│   ├── tool_composition.json
│   ├── card_templates.json
│   ├── card_eligibility_rules.json
│   ├── challenges.json
│   └── knowledge_graph_meta_schema.json
│
└── infrastructure/
    ├── docker/                 # docker-compose.yml lives at root now for simplicity
    └── terraform/
        ├── modules/            # Reusable Terraform modules
        ├── env-aws/            # AWS environment configurations (staging, prod)
        └── env-tencent/        # Tencent Cloud environment configurations
```

---

## **3. V9.5 Unified Docker Strategy**

The use of individual `Dockerfile`s in each service/worker directory is deprecated in favor of a single, powerful root `Dockerfile` that leverages Turborepo's build capabilities.

### **3.1 Root `Dockerfile`**

**Location:** `/Dockerfile`

This file is designed to build a production-ready image for any Node.js application within the monorepo.

```dockerfile
# Stage 1: Build dependencies
FROM node:18-alpine AS base
WORKDIR /app

# Install pnpm
RUN npm install -g pnpm

# Copy only package manifests and workspace config
COPY package.json pnpm-lock.yaml pnpm-workspace.yaml ./

# Install all dependencies for all workspaces
RUN pnpm install --frozen-lockfile

# Stage 2: Build the source code
FROM base AS builder
WORKDIR /app

# Copy the entire monorepo source code
COPY . .

# Use Turborepo to build all applications and packages
# This leverages the caching and dependency graph features of Turbo
RUN pnpm turbo run build

# Stage 3: Production Image
FROM node:18-alpine AS runner
WORKDIR /app

# Argument to specify which app/service to run
ARG APP_NAME

# Copy only necessary files from the builder stage
COPY --from=builder /app/node_modules ./node_modules
COPY --from=builder /app/package.json ./package.json

# Copy the built output of the specific application/service
# Example: copies 'services/dialogue-service/dist' to './dist'
COPY --from=builder /app/services/${APP_NAME}/dist ./dist

# Copy the centralized config directory
COPY --from=builder /app/config ./config

# Set the command to run the specific application
# Assumes the 'dist/index.js' is the entry point for all services/workers.
CMD ["node", "dist/index.js"]
```

### **3.2 Root `docker-compose.yml`**

This file orchestrates the entire local development environment, including all databases, services, and workers, using the single root `Dockerfile`.

**Location:** `/docker-compose.yml`

```yaml
version: '3.8'

services:
  # --- DATABASES ---
  postgres:
    image: postgres:16-alpine
    ports:
      - "5432:5432"
    environment:
      - POSTGRES_USER=${POSTGRES_USER}
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
      - POSTGRES_DB=${POSTGRES_DB}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U ${POSTGRES_USER} -d ${POSTGRES_DB}"]
      interval: 5s
      timeout: 5s
      retries: 5

  neo4j:
    image: neo4j:5
    ports:
      - "7474:7474" # HTTP
      - "7687:7687" # Bolt
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD}
    volumes:
      - neo4j_data:/data

  weaviate:
    image: semitechnologies/weaviate:latest
    ports:
      - "8080:8080"
    environment:
      - QUERY_DEFAULTS_LIMIT=25
      - AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED=true
      - PERSISTENCE_DATA_PATH=/var/lib/weaviate
      - DEFAULT_VECTORIZER_MODULE=none # V9.5: Embeddings are external
      - CLUSTER_HOSTNAME=node1
    volumes:
      - weaviate_data:/var/lib/weaviate

  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    # V9.5: Enable keyspace notifications for conversation timeouts
    command: redis-server --notify-keyspace-events KEA

  # --- BACKEND SERVICES & WORKERS ---
  api-gateway:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: api-gateway
    ports:
      - "3000:3000"
    env_file: .env
    depends_on:
      postgres: { condition: service_healthy }
      dialogue-service: { condition: service_started } # or healthcheck
      card-service: { condition: service_started }

  dialogue-service:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: dialogue-service
    env_file: .env
    depends_on:
      - redis
      - postgres
      - neo4j
      - weaviate

  card-service:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: card-service
    env_file: .env
    depends_on:
      - postgres
      - redis
  
  ingestion-worker:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: ingestion-worker
    env_file: .env
    depends_on:
      - redis
      - postgres
      - neo4j
      - weaviate

  insight-worker:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: insight-worker
    env_file: .env
    depends_on:
      - redis
      - postgres
      - neo4j

  card-worker: # NEW
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: card-worker
    env_file: .env
    depends_on:
      - redis
      - postgres

  graph-projection-worker: # NEW
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: graph-projection-worker
    env_file: .env
    depends_on:
      - redis
      - neo4j
      - weaviate

  conversation-timeout-worker: # NEW
    build:
      context: .
      dockerfile: Dockerfile
      args:
        APP_NAME: conversation-timeout-worker
    env_file: .env
    depends_on:
      - redis

volumes:
  postgres_data:
  neo4j_data:
  weaviate_data:
  redis_data:
```

This V9.5 monorepo and deployment structure provides a clean, logical, and highly efficient foundation for building and running the 2dots1line system. It reflects the architectural separation of concerns and simplifies the development lifecycle.