### **Canonical Guide: The V9.2 `HolisticAnalysisTool` (Composite Tool)**

#### **1. Core Job Responsibility & Philosophy**

The `HolisticAnalysisTool` is a **composite tool** used exclusively by the `IngestionAnalyst` worker. Its primary responsibility is to perform a comprehensive, LLM-driven analysis of a completed conversation transcript, transforming unstructured dialogue into structured knowledge and a forward-looking context package.

**Philosophy:** It embodies the "Single Synthesis Call" principle for the `IngestionAnalyst`. Instead of the `IngestionAnalyst` making multiple LLM calls for summarization, entity extraction, growth event detection, etc., it makes one call to this composite tool, which in turn makes one highly structured call to its configured atomic `LLMChatTool`.

**Location:** `packages/tools/composite/HolisticAnalysisTool.ts`

**Instantiated By:** The `ToolRegistry` at the initialization of the `IngestionAnalyst` worker, based on configuration in `config/tool_composition.json`.

#### **2. Input & Output Contracts**

**Input to `HolisticAnalysisTool.execute()`:**

```typescript
interface HolisticAnalysisInput {
  userId: string;
  fullConversationTranscript: string; // Formatted: "USER: ...\nASSISTANT: ..."
  userMemoryProfile: UserMemoryProfileData; // From User.memory_profile
  knowledgeGraphSchema: KnowledgeGraphSchemaData; // From User.knowledge_graph_schema
  // Optional: Accumulated flags from TurnContextPackages if needed for nuances
  // accumulatedTurnFlags?: string[]; 
}
```

**Output of `HolisticAnalysisTool.execute()` (A Single JSON Object Matching LLM Output):**

This is the exact structure the internal `LLMChatTool` is prompted to return.

```json
interface HolisticAnalysisOutput {
  persistence_payload: {
    conversation_summary: string;
    conversation_importance_score: number; // 1-10
    extracted_memory_units: Array<{
      temp_id: string; // e.g., "mem_1"
      title: string;
      content: string; // Detailed summary of the memory
      source_type: string; // e.g., "conversation_extraction"
      creation_ts: string; // ISO8601, inferred
    }>;
    extracted_concepts: Array<{
      name: string;
      type: string; // Must be valid per KnowledgeGraphSchema
      description: string;
    }>;
    new_relationships: Array<{
      source_temp_id_or_existing_id: string; // "mem_1" or existing Concept/MemoryUnit UUID
      target_name_or_existing_id: string;    // Concept name or existing Concept/MemoryUnit UUID
      relationship_label: string; // Must be valid per KnowledgeGraphSchema
    }>;
    detected_growth_events: Array<{
      dim_key: string; // Valid 6D growth dimension key
      delta: number;
      rationale: string; // AI-generated explanation
    }>;
  };
  forward_looking_context: { // This is the NextConversationContextPackage
    proactive_greeting: string;
    unresolved_topics_for_next_convo: Array<{
      topic: string;
      summary_of_unresolution: string;
      suggested_question: string;
    }>;
    suggested_initial_focus: string; // Formerly "suggested_initial_directive" for DialogueAgent
  };
}
```

#### **3. Internal Components (Injected by `ToolRegistry`)**

Based on `config/tool_composition.json` for `"ingestionAnalyst"`, this tool will be constructed with:

1.  **`llmChatTool: LLMChatTool`**: An instance of an atomic `LLMChatTool` (e.g., configured to use `google_gemini_1.5_pro`). This is its primary workhorse.
2.  **`textEmbeddingTool: TextEmbeddingTool` (Optional but Recommended):** An instance of an atomic `TextEmbeddingTool`. While the LLM output provides structured data, the `IngestionAnalyst` worker (after receiving output from this tool) will still need to create embeddings for new `MemoryUnit` content and `Concept` descriptions before updating Weaviate. This tool isn't *used by* `HolisticAnalysisTool` directly during its LLM call but is a dependency for the overall ingestion process. *Correction: The `HolisticAnalysisTool` itself doesn't do embedding. The `IngestionAnalyst` worker, after getting the text from this tool's output, will call a separate embedding tool.*

#### **4. Detailed Workflow of `HolisticAnalysisTool.execute()`**

This method orchestrates the "Single Synthesis Call."

```
                                   ┌──────────────────────────────────┐
                                   │ `IngestionAnalyst` calls         │
                                   │ `HolisticAnalysisTool.execute()` │
                                   │ (with transcript, userProfile,   │
                                   │  knowledgeGraphSchema)           │
                                   └─────────────────┬────────────────┘
                                                     │ 1. Input received
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Internal `buildAnalysisPrompt()` │
                                   │ - Formats all inputs into a single │
                                   │   master prompt for the LLM.     │
                                   │ - Includes CoreIdentity (Analyst subset)│
                                   │ - Includes detailed instructions │
                                   │   & the required JSON output schema.│
                                   └─────────────────┬────────────────┘
                                                     │ 2. Master prompt generated
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Calls injected `this.llmChatTool.execute()`│
                                   │ (with the master prompt)         │
                                   └─────────────────┬────────────────┘
                                                     │ 3. LLM processes and returns
                                                     │    a single JSON string
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Internal `validateAndParseOutput()`│
                                   │ - Parses the JSON string.        │
                                   │ - Validates against the expected │
                                   │   `HolisticAnalysisOutput` schema. │
                                   │ - Handles potential parsing errors.│
                                   └─────────────────┬────────────────┘
                                                     │ 4. Validated JSON object
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Returns `HolisticAnalysisOutput` │
                                   │ to the `IngestionAnalyst` worker.│
                                   └──────────────────────────────────┘
```

**Step-by-Step Implementation Details:**

1.  **`constructor(llmChatTool: LLMChatTool)`:**
    *   Receives the pre-configured atomic `LLMChatTool` instance from the `ToolRegistry`.
    *   Stores it as `this.llmChatTool`.

2.  **`async execute(input: HolisticAnalysisInput): Promise<HolisticAnalysisOutput>`:**
    *   **`buildAnalysisPrompt(input)` (Private Method):**
        1.  Takes `input.fullConversationTranscript`, `input.userMemoryProfile`, `input.knowledgeGraphSchema`.
        2.  Constructs the master prompt string. This involves:
            *   Prepending relevant sections of the `CoreIdentity` (specifically defining the role of an "expert knowledge analyst").
            *   Embedding the `UserMemoryProfile` within an XML tag (e.g., `<user_memory_profile>...</user_memory_profile>`).
            *   Embedding the `KnowledgeGraphSchema` within an XML tag (e.g., `<knowledge_graph_schema>...</knowledge_graph_schema>`).
            *   Embedding the `FullConversationTranscript` (e.g., `<conversation_transcript>...</conversation_transcript>`).
            *   Appending the detailed `Instructions` that specify the task (holistic analysis) and the **exact required JSON output structure** for `HolisticAnalysisOutput` (both `persistence_payload` and `forward_looking_context`).
        3.  Returns the complete prompt string.
    *   **Call `this.llmChatTool.execute({ prompt: generatedMasterPrompt })`:**
        *   Sends the comprehensive prompt to the LLM.
        *   Awaits the LLM's response, which is expected to be a JSON string.
    *   **`validateAndParseOutput(llmJsonResponse: string)` (Private Method):**
        1.  Attempts to `JSON.parse(llmJsonResponse)`.
        2.  Validates the parsed object against a Zod schema (or similar validation library) defined for `HolisticAnalysisOutput`. This ensures all required fields are present and have the correct types.
        3.  If parsing or validation fails, throws a specific error (e.g., `MalformedLLMOutputError`) that the `IngestionAnalyst` worker can catch and handle (e.g., by logging the error and moving the job to a dead-letter queue).
        4.  Returns the validated `HolisticAnalysisOutput` object.
    *   Returns the result from `validateAndParseOutput`.

#### **5. Prompt Engineering Snippet for `LLMChatTool` (Inside `buildAnalysisPrompt`)**

```xml
<system_identity>
  You are a meticulous and insightful Knowledge Analyst. Your role is to transform raw conversation transcripts into structured knowledge and actionable future context.
  You MUST adhere strictly to the JSON output format specified.
</system_identity>

<user_memory_profile>
  <!-- JSON content of User.memory_profile -->
</user_memory_profile>

<knowledge_graph_schema>
  <!-- JSON content of User.knowledge_graph_schema -->
  <!-- Use this to ensure extracted 'type' for concepts and 'relationship_label' are valid. -->
  <!-- When identifying existing concepts, prefer matches from the UserMemoryProfile if available. -->
</knowledge_graph_schema>

<conversation_transcript>
  <!-- Full formatted transcript: USER: ... ASSISTANT: ... -->
</conversation_transcript>

<instructions>
Analyze the provided <conversation_transcript> in the context of the <user_memory_profile> and adhere to the <knowledge_graph_schema>.
Your entire output MUST be a single, valid JSON object with the following structure:

{
  "persistence_payload": {
    "conversation_summary": "A concise, neutral, one-paragraph summary of the main topics, decisions, and emotional tone shifts in the conversation.",
    "conversation_importance_score": /* Integer 1-10, considering depth, emotional weight, relevance to user's profile, and novelty */,
    "extracted_memory_units": [
      {
        "temp_id": "mem_UNIQUE_ID_1", // Use unique temporary IDs starting with "mem_"
        "title": "A clear, concise title for this distinct memory or event (max 15 words).",
        "content": "A detailed, self-contained summary of this specific memory or event, capturing who, what, where, when, why, and how. Extract verbatim key phrases where appropriate.",
        "source_type": "conversation_extraction",
        "creation_ts": "The ISO8601 timestamp when the event described in this memory unit OCCURRED, as inferred from the transcript. If not inferable, use the conversation's end time."
      }
      // ... more memory units if distinct events were discussed ...
    ],
    "extracted_concepts": [
      {
        "name": "The proper name of the concept/entity (e.g., 'Project Phoenix', 'Sarah Adams', 'Anxiety').",
        "type": "The concept type (must be from <knowledge_graph_schema>.concept_types or a common type like 'person', 'organization', 'topic', 'goal', 'value', 'skill', 'emotion', 'project', 'event_theme').",
        "description": "A brief, defining description of this concept based on the conversation (max 30 words)."
      }
      // ... more concepts ...
    ],
    "new_relationships": [ // Define connections between new memories, new concepts, and existing concepts (from UserMemoryProfile)
      {
        "source_temp_id_or_existing_id": "ID of source: either a 'mem_UNIQUE_ID_X' from above, or an existing Concept UUID from UserMemoryProfile if mentioned.",
        "target_name_or_existing_id": "Name of target concept (if new) OR UUID of existing Concept from UserMemoryProfile.",
        "relationship_label": "A relationship type from <knowledge_graph_schema>.relationship_types (e.g., 'discusses_topic', 'expresses_emotion', 'sets_goal', 'related_to_person')."
      }
      // ... more relationships ...
    ],
    "detected_growth_events": [
      {
        "dim_key": "A valid 6D growth key (e.g., 'know_self', 'act_world').",
        "delta": /* A float value (e.g., 0.1 to 0.5) representing impact. */,
        "rationale": "A one-sentence explanation, grounded in the transcript, for why this growth event occurred (e.g., 'User reflected on a past failure and identified a new coping strategy, demonstrating Know-Self.')."
      }
      // ... more growth events if applicable ...
    ]
  },
  "forward_looking_context": { // This is the NextConversationContextPackage
    "proactive_greeting": "A warm, context-aware greeting for the DialogueAgent to use at the start of the user's NEXT conversation, referencing a key topic from THIS conversation.",
    "unresolved_topics_for_next_convo": [
      {
        "topic": "A brief description of an unresolved topic or open loop from THIS conversation.",
        "summary_of_unresolution": "Why it was left unresolved or needs more exploration.",
        "suggested_question": "A specific, open-ended question the DialogueAgent can ask to re-engage this topic in the next conversation."
      }
      // ... up to 2-3 unresolved topics ...
    ],
    "suggested_initial_focus": "A brief suggestion for what the DialogueAgent should primarily focus on at the start of the next conversation (e.g., 'Validating user's feelings about X', 'Exploring solutions for Y')."
  }
}
Do not include any text outside this JSON structure.
</instructions>
```

This detailed guide for the `HolisticAnalysisTool` ensures it acts as a powerful, specialized component within the `IngestionAnalyst`'s workflow, perfectly aligning with the V9.2 architecture's principles of single synthesis calls and clear separation of concerns.