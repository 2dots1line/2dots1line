### **`2.2.1_V9.6_HolisticAnalysisTool.md`**

---

# **V9.6 Canonical Guide: The `HolisticAnalysisTool` (Composite Tool)**

**Document Version:** 9.6 (Updated with Validation Schemas)
**Purpose:** To provide a definitive, deep-dive specification for the `HolisticAnalysisTool`. This composite tool is the cognitive core of the `IngestionAnalyst` worker, responsible for transforming unstructured conversation transcripts into structured knowledge and forward-looking context.

## **1. Core Job Responsibility & Philosophy**

The `HolisticAnalysisTool` is a **composite tool** used exclusively by the `IngestionAnalyst` worker. Its primary responsibility is to perform a comprehensive, LLM-driven analysis of a completed conversation transcript, transforming unstructured dialogue into structured knowledge and a forward-looking context package.

**Philosophy:** It embodies the "Single Synthesis Call" principle for the `IngestionAnalyst`. Instead of the `IngestionAnalyst` making multiple LLM calls for summarization, entity extraction, growth event detection, etc., it makes one call to this composite tool, which in turn makes one highly structured call to its configured atomic `LLMChatTool`.

**Location:** `packages/tools/composite/HolisticAnalysisTool.ts`

**Instantiated By:** The `ToolRegistry` at the initialization of the `IngestionAnalyst` worker, based on configuration in `config/tool_composition.json`.

## **2. Input & Output Contracts**

### **Input to `HolisticAnalysisTool.execute()`:**

```typescript
interface HolisticAnalysisInput {
  userId: string;
  fullConversationTranscript: string; // Formatted: "USER: ...\nASSISTANT: ..."
  userMemoryProfile: UserMemoryProfileData; // From User.memory_profile
  knowledgeGraphSchema: KnowledgeGraphSchemaData; // From User.knowledge_graph_schema
  // Optional: Accumulated flags from TurnContextPackages if needed for nuances
  // accumulatedTurnFlags?: string[]; 
}
```

### **Output of `HolisticAnalysisTool.execute()` (A Single JSON Object Matching LLM Output):**

This is the exact structure the internal `LLMChatTool` is prompted to return.

```typescript
interface HolisticAnalysisOutput {
  persistence_payload: {
    conversation_summary: string;
    conversation_importance_score: number; // 1-10
    extracted_memory_units: Array<{
      temp_id: string; // e.g., "mem_1"
      title: string;
      content: string; // Detailed summary of the memory
      source_type: string; // e.g., "conversation_extraction"
      creation_ts: string; // ISO8601, inferred
    }>;
    extracted_concepts: Array<{
      name: string;
      type: string; // Must be valid per KnowledgeGraphSchema
      description: string;
    }>;
    new_relationships: Array<{
      source_temp_id_or_existing_id: string; // "mem_1" or existing Concept/MemoryUnit UUID
      target_name_or_existing_id: string;    // Concept name or existing Concept/MemoryUnit UUID
      relationship_label: string; // Must be valid per KnowledgeGraphSchema
    }>;
    detected_growth_events: Array<{
      dim_key: string; // Valid 6D growth dimension key
      delta: number;
      rationale: string; // AI-generated explanation
    }>;
  };
  forward_looking_context: { // This is the NextConversationContextPackage
    proactive_greeting: string;
    unresolved_topics_for_next_convo: Array<{
      topic: string;
      summary_of_unresolution: string;
      suggested_question: string;
    }>;
    suggested_initial_focus: string; // Formerly "suggested_initial_directive" for DialogueAgent
  };
}
```

### **Zod Validation Schema** *(New - V9.6)*

```typescript
// packages/tools/composite/src/schemas/HolisticAnalysisOutput.schema.ts
import { z } from 'zod';

export const HolisticAnalysisOutputSchema = z.object({
  persistence_payload: z.object({
    conversation_summary: z.string().min(10).max(500),
    conversation_importance_score: z.number().int().min(1).max(10),
    extracted_memory_units: z.array(z.object({
      temp_id: z.string().regex(/^mem_[a-zA-Z0-9_]+$/),
      title: z.string().min(5).max(150),
      content: z.string().min(20).max(2000),
      source_type: z.enum(['conversation_extraction', 'journal_entry', 'user_input', 'system_generated']),
      creation_ts: z.string().datetime()
    })).max(10), // Reasonable limit for extracted memories per conversation
    
    extracted_concepts: z.array(z.object({
      name: z.string().min(1).max(100),
      type: z.string().min(1).max(50),
      description: z.string().min(5).max(300)
    })).max(20), // Reasonable limit for extracted concepts per conversation
    
    new_relationships: z.array(z.object({
      source_temp_id_or_existing_id: z.string().min(1),
      target_name_or_existing_id: z.string().min(1),
      relationship_label: z.string().min(1).max(50)
    })).max(30), // Reasonable limit for relationships per conversation
    
    detected_growth_events: z.array(z.object({
      dim_key: z.enum(['know_self', 'know_world', 'act_self', 'act_world', 'show_self', 'show_world']),
      delta: z.number().min(-2.0).max(2.0), // Reasonable range for growth deltas
      rationale: z.string().min(10).max(200)
    })).max(6) // Maximum one event per dimension
  }),
  
  forward_looking_context: z.object({
    proactive_greeting: z.string().min(10).max(300),
    unresolved_topics_for_next_convo: z.array(z.object({
      topic: z.string().min(3).max(100),
      summary_of_unresolution: z.string().min(10).max(200),
      suggested_question: z.string().min(10).max(150)
    })).max(5), // Maximum 5 unresolved topics to avoid overwhelming
    suggested_initial_focus: z.string().min(10).max(200)
  })
});

// Type inference from schema
export type HolisticAnalysisOutput = z.infer<typeof HolisticAnalysisOutputSchema>;

// Validation helper function
export function validateHolisticAnalysisOutput(data: unknown): HolisticAnalysisOutput {
  return HolisticAnalysisOutputSchema.parse(data);
}
```

## **3. Internal Components (Injected by `ToolRegistry`)**

Based on `config/tool_composition.json` for `"ingestionAnalyst"`, this tool will be constructed with:

1.  **`llmChatTool: LLMChatTool`**: An instance of an atomic `LLMChatTool` (e.g., configured to use `deepseek_v2_pro`). This is its primary workhorse.
2.  **`textEmbeddingTool: TextEmbeddingTool` (Optional but Recommended):** An instance of an atomic `TextEmbeddingTool`. While the LLM output provides structured data, the `IngestionAnalyst` worker (after receiving output from this tool) will still need to create embeddings for new `MemoryUnit` content and `Concept` descriptions before updating Weaviate.

## **4. Detailed Workflow of `HolisticAnalysisTool.execute()`**

This method orchestrates the "Single Synthesis Call."

```
                                   ┌──────────────────────────────────┐
                                   │ `IngestionAnalyst` calls         │
                                   │ `HolisticAnalysisTool.execute()` │
                                   │ (with transcript, userProfile,   │
                                   │  knowledgeGraphSchema)           │
                                   └─────────────────┬────────────────┘
                                                     │ 1. Input received
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Internal `buildAnalysisPrompt()` │
                                   │ - Formats all inputs into a single │
                                   │   master prompt for the LLM.     │
                                   │ - Includes CoreIdentity (Analyst subset)│
                                   │ - Includes detailed instructions │
                                   │   & the required JSON output schema.│
                                   └─────────────────┬────────────────┘
                                                     │ 2. Master prompt generated
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Calls injected `this.llmChatTool.execute()`│
                                   │ (with the master prompt)         │
                                   └─────────────────┬────────────────┘
                                                     │ 3. LLM processes and returns
                                                     │    a single JSON string
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Internal `validateAndParseOutput()`│
                                   │ - Parses the JSON string.        │
                                   │ - Validates against Zod schema   │
                                   │ - Handles potential parsing errors.│
                                   └─────────────────┬────────────────┘
                                                     │ 4. Validated JSON object
                                                     ▼
                                   ┌──────────────────────────────────┐
                                   │ Returns `HolisticAnalysisOutput` │
                                   │ to the `IngestionAnalyst` worker.│
                                   └──────────────────────────────────┘
```

### **Step-by-Step Implementation Details:**

1.  **`constructor(llmChatTool: LLMChatTool)`:**
    *   Receives the pre-configured atomic `LLMChatTool` instance from the `ToolRegistry`.
    *   Stores it as `this.llmChatTool`.

2.  **`async execute(input: HolisticAnalysisInput): Promise<HolisticAnalysisOutput>`:**
    *   **`buildAnalysisPrompt(input)` (Private Method):**
        1.  Takes `input.fullConversationTranscript`, `input.userMemoryProfile`, `input.knowledgeGraphSchema`.
        2.  Constructs the master prompt string. This involves:
            *   Prepending relevant sections of the `CoreIdentity` (specifically defining the role of an "expert knowledge analyst").
            *   Embedding the `UserMemoryProfile` within an XML tag (e.g., `<user_memory_profile>...</user_memory_profile>`).
            *   Embedding the `KnowledgeGraphSchema` within an XML tag (e.g., `<knowledge_graph_schema>...</knowledge_graph_schema>`).
            *   Embedding the `FullConversationTranscript` (e.g., `<conversation_transcript>...</conversation_transcript>`).
            *   Appending the detailed `Instructions` that specify the task (holistic analysis) and the **exact required JSON output structure** for `HolisticAnalysisOutput` (both `persistence_payload` and `forward_looking_context`).
        3.  Returns the complete prompt string.
    *   **Call `this.llmChatTool.execute({ prompt: generatedMasterPrompt })`:**
        *   Sends the comprehensive prompt to the LLM.
        *   Awaits the LLM's response, which is expected to be a JSON string.
    *   **`validateAndParseOutput(llmJsonResponse: string)` (Private Method):** *(Updated - V9.6)*
        1.  Attempts to `JSON.parse(llmJsonResponse)`.
        2.  Validates the parsed object using the `HolisticAnalysisOutputSchema` from the Zod schema. This ensures all required fields are present and have the correct types, lengths, and formats.
        3.  If parsing fails, throws a `JSONParseError` with the original response.
        4.  If validation fails, throws a `ValidationError` with detailed field-level error messages.
        5.  Returns the validated `HolisticAnalysisOutput` object.
    *   Returns the result from `validateAndParseOutput`.

### **Error Handling Strategy** *(New - V9.6)*

```typescript
// Custom error types for better error handling
export class HolisticAnalysisError extends Error {
  constructor(message: string, public cause?: Error) {
    super(message);
    this.name = 'HolisticAnalysisError';
  }
}

export class JSONParseError extends HolisticAnalysisError {
  constructor(public rawResponse: string) {
    super('Failed to parse LLM response as JSON');
    this.name = 'JSONParseError';
  }
}

export class ValidationError extends HolisticAnalysisError {
  constructor(public validationErrors: z.ZodError) {
    super(`Validation failed: ${validationErrors.message}`);
    this.name = 'ValidationError';
  }
}

// Implementation in validateAndParseOutput method
private validateAndParseOutput(llmJsonResponse: string): HolisticAnalysisOutput {
  let parsed: unknown;
  
  try {
    parsed = JSON.parse(llmJsonResponse);
  } catch (error) {
    throw new JSONParseError(llmJsonResponse);
  }
  
  try {
    return validateHolisticAnalysisOutput(parsed);
  } catch (error) {
    if (error instanceof z.ZodError) {
      throw new ValidationError(error);
    }
    throw new HolisticAnalysisError('Unknown validation error', error as Error);
  }
}
```

## **5. Prompt Engineering Snippet for `LLMChatTool` (Inside `buildAnalysisPrompt`)**

```xml
<system_identity>
  You are a meticulous and insightful Knowledge Analyst. Your role is to transform raw conversation transcripts into structured knowledge and actionable future context.
  You MUST adhere strictly to the JSON output format specified.
</system_identity>

<user_memory_profile>
  <!-- JSON content of User.memory_profile -->
</user_memory_profile>

<knowledge_graph_schema>
  <!-- JSON content of User.knowledge_graph_schema -->
  <!-- Use this to ensure extracted 'type' for concepts and 'relationship_label' are valid. -->
  <!-- When identifying existing concepts, prefer matches from the UserMemoryProfile if available. -->
</knowledge_graph_schema>

<conversation_transcript>
  <!-- Full formatted transcript: USER: ... ASSISTANT: ... -->
</conversation_transcript>

<instructions>
Analyze the provided <conversation_transcript> in the context of the <user_memory_profile> and adhere to the <knowledge_graph_schema>.
Your entire output MUST be a single, valid JSON object with the following structure:

{
  "persistence_payload": {
    "conversation_summary": "A concise, neutral, one-paragraph summary of the main topics, decisions, and emotional tone shifts in the conversation.",
    "conversation_importance_score": /* Integer 1-10, considering depth, emotional weight, relevance to user's profile, and novelty */,
    "extracted_memory_units": [
      {
        "temp_id": "mem_UNIQUE_ID_1", // Use unique temporary IDs starting with "mem_"
        "title": "A clear, concise title for this distinct memory or event (max 15 words).",
        "content": "A detailed, self-contained summary of this specific memory or event, capturing who, what, where, when, why, and how. Extract verbatim key phrases where appropriate.",
        "source_type": "conversation_extraction",
        "creation_ts": "The ISO8601 timestamp when the event described in this memory unit OCCURRED, as inferred from the transcript. If not inferable, use the conversation's end time."
      }
      // ... more memory units if distinct events were discussed ...
    ],
    "extracted_concepts": [
      {
        "name": "The proper name of the concept/entity (e.g., 'Project Phoenix', 'Sarah Adams', 'Anxiety').",
        "type": "The concept type (must be from <knowledge_graph_schema>.concept_types or a common type like 'person', 'organization', 'topic', 'goal', 'value', 'skill', 'emotion', 'project', 'event_theme').",
        "description": "A brief, defining description of this concept based on the conversation (max 30 words)."
      }
      // ... more concepts ...
    ],
    "new_relationships": [ // Define connections between new memories, new concepts, and existing concepts (from UserMemoryProfile)
      {
        "source_temp_id_or_existing_id": "ID of source: either a 'mem_UNIQUE_ID_X' from above, or an existing Concept UUID from UserMemoryProfile if mentioned.",
        "target_name_or_existing_id": "Target: either a concept name from extracted_concepts above, or an existing Concept UUID from UserMemoryProfile if mentioned.",
        "relationship_label": "A specific relationship label (must be from <knowledge_graph_schema>.universal_relationship_labels, e.g., 'supports', 'causes', 'influences')."
      }
      // ... more relationships ...
    ],
    "detected_growth_events": [ // Based on the 6D Growth Matrix
      {
        "dim_key": "One of: 'know_self', 'know_world', 'act_self', 'act_world', 'show_self', 'show_world'",
        "delta": /* Float between -2.0 and 2.0 representing growth/regression magnitude */,
        "rationale": "Brief explanation of why this growth event was detected (max 50 words)."
      }
      // ... events for other dimensions if applicable ...
    ]
  },
  "forward_looking_context": {
    "proactive_greeting": "A warm, personalized greeting for the next conversation that acknowledges key insights or emotions from this conversation.",
    "unresolved_topics_for_next_convo": [
      {
        "topic": "A specific topic or question that was raised but not fully resolved.",
        "summary_of_unresolution": "Brief explanation of what remains unaddressed.",
        "suggested_question": "A thoughtful follow-up question to explore this topic further."
      }
      // ... more unresolved topics if any ...
    ],
    "suggested_initial_focus": "A strategic suggestion for what the DialogueAgent should focus on or prioritize in the next conversation."
  }
}

CRITICAL VALIDATION REQUIREMENTS:
- temp_id values must start with "mem_" and be unique
- conversation_importance_score must be an integer between 1-10
- concept types must be valid per the knowledge_graph_schema
- relationship_labels must be valid per the knowledge_graph_schema  
- dim_key values must be exactly one of the 6 growth dimensions
- delta values must be numbers between -2.0 and 2.0
- All string fields must meet minimum length requirements (titles ≥5 chars, content ≥20 chars, etc.)
</instructions>
```

This updated guide for the V9.6 `HolisticAnalysisTool` now includes comprehensive validation schemas and error handling, ensuring reliable output processing and better debugging capabilities for the `IngestionAnalyst` worker.