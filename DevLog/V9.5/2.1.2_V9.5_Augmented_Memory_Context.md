### **`2.1.2_V9.6_Augmented_Memory_Context.md`**

---

# **V9.6 Definitive Canonical Guide: The `AugmentedMemoryContext`**

**Document Version:** 9.6 (Updated with Error Handling)
**Purpose:** To provide the canonical specification for the `AugmentedMemoryContext` data structure, which serves as the direct output of the `HybridRetrievalTool` and input to the `DialogueAgent`'s contextual response generation.

## **1. Purpose**

To provide the `DialogueAgent`'s subsequent LLM call with specific, detailed, and intelligently prioritized information retrieved from the user's knowledge graph, including comprehensive error reporting for partial failures or degraded results.

## **2. Structure and JSON Template (V9.6 - With Error Handling)**

This structure directly maps to the `Output Contract` defined in `2.1.1_V9.6_HybridRetrievalTool.md` for `HybridRetrievalTool.execute()`.

```json
// Definitive Structure for AugmentedMemoryContext (V9.6)
// Output of HybridRetrievalTool V9.6
{
  "retrieved_memory_units": [ // Corresponds to HRT Output: AugmentedMemoryContext.retrievedMemoryUnits
    {
      "muid": "uuid-mu-1",
      "title": "Brainstorming Session for Project Phoenix",
      "content_snippet": "Key discussion points included timeline adjustments and resource allocation...", // HRT provides snippet
      "creation_ts": "2025-06-10T10:00:00Z",
      "source_type": "conversation_extraction",
      "importance_score": 8.5, // From MemoryUnit table
      "final_retrieval_score": 0.92, // Calculated by HRT EntityScorer
      "score_breakdown": { // Optional, if HRT's ScoringMetadata includes it
        "semantic": 0.85,
        "recency": 0.90,
        "salience": 0.95,
        "preference": 0.98
      },
      "connected_concept_ids_and_names": [
        { "id": "uuid-concept-A", "name": "Project Phoenix" },
        { "id": "uuid-concept-B", "name": "Team Bandwidth" }
      ]
      // Other fields from MemoryUnit model as needed for LLM context
    }
    // ... more MemoryUnit objects ...
  ],
  "retrieved_concepts": [ // Corresponds to HRT Output: AugmentedMemoryContext.retrievedConcepts
    {
      "id": "uuid-concept-A",
      "name": "Project Phoenix",
      "type": "project",
      "description_snippet": "A key initiative focused on developing the next-gen platform...", // HRT provides snippet
      "status": "active",
      "salience": 0.9, // From Concept table
      "final_retrieval_score": 0.95,
      "score_breakdown": { /* ... */ },
      "related_top_memory_unit_ids_and_titles": [
        { "id": "uuid-mu-1", "title": "Brainstorming Session for Project Phoenix" }
      ],
      "key_properties_values": { // HRT populates this based on schema & relevance
        "target_completion_date": "2025-12-31",
        "project_lead_name": "Sarah Adams"
      }
      // Other fields from Concept model as needed
    }
    // ... more Concept objects ...
  ],
  "retrieved_artifacts": [ // Optional, Corresponds to HRT Output: AugmentedMemoryContext.retrievedArtifacts
    {
      "id": "uuid-da-1",
      "artifact_type": "insight_summary",
      "title": "Insight: Link between Exercise and Creativity",
      "content_snippet": "Analysis shows a correlation...", // HRT provides snippet
      "created_at": "2025-06-01T15:00:00Z",
      "final_retrieval_score": 0.75,
      "score_breakdown": { /* ... */ }
      // Other fields from DerivedArtifact model as needed
    }
    // ... more DerivedArtifact objects ...
  ],
  "retrieval_summary": "Retrieved 5 relevant items (2 Memories, 3 Concepts) based on key phrases 'Project Phoenix' and 'team meeting'. Top results prioritized by recency and salience.", // Corresponds to HRT Output: AugmentedMemoryContext.retrievalSummary. This summary is generated by HRT based on its process.
  "scoring_details": { // Optional, Corresponds to HRT Output: AugmentedMemoryContext.scoringDetails
    "total_candidates_considered": 15, // From HRT
    "seed_entities_identified_from_key_phrases": 4, // Example metric HRT could provide
    "graph_traversal_depth_used": 2, // Example metric
    "weights_used": { // The actual weights used for this retrieval
      "alpha_semantic_similarity": 0.4,
      "beta_recency": 0.25,
      "gamma_salience": 0.25,
      "delta_user_preference": 0.1
    }
  },
  "unmatched_key_phrases": [ // Key phrases for which HRT found no strong initial semantic matches in Weaviate
    "that book on 'deep work'"
  ],
  "errors": [ // NEW V9.6: Comprehensive error reporting for partial failures
    {
      "stage": "Weaviate", // "Weaviate" | "Neo4j" | "PostgreSQL" | "Scoring"
      "error": "Query timed out after 5000ms for phrase 'deep work strategies'",
      "impact": "partial_results", // "partial_results" | "degraded_quality" | "fallback_used"
      "affected_phrases": ["deep work strategies"],
      "fallback_action": "Used cached results from previous query",
      "timestamp": "2025-06-15T14:32:01Z"
    },
    {
      "stage": "Neo4j",
      "error": "Connection pool exhausted during graph traversal",
      "impact": "degraded_quality",
      "affected_entities": ["uuid-concept-C", "uuid-concept-D"],
      "fallback_action": "Skipped relationship expansion for 2 seed entities",
      "timestamp": "2025-06-15T14:32:03Z"
    }
  ],
  "performance_metadata": { // NEW V9.6: Performance insights for monitoring and optimization
    "total_execution_time_ms": 1847,
    "stage_timings": {
      "key_phrase_processing": 45,
      "weaviate_semantic_search": 520,
      "neo4j_graph_traversal": 680,
      "scoring_and_ranking": 125,
      "postgresql_hydration": 477
    },
    "result_counts": {
      "weaviate_candidates": 12,
      "neo4j_candidates": 8,
      "final_results_after_scoring": 5
    },
    "cache_hits": {
      "weaviate_query_cache": 2,
      "neo4j_session_cache": 1,
      "postgresql_connection_pool": 0
    }
  }
}
```

### **Key Enhancements in V9.6:**

#### **1. Comprehensive Error Reporting**
*   **`errors` Array:** Captures partial failures across all HRT stages without breaking the entire retrieval process
*   **Granular Impact Assessment:** Categorizes error impact to help the DialogueAgent understand result quality
*   **Fallback Actions:** Documents what the HRT did to mitigate each error
*   **Stage-Specific Context:** Provides relevant context for each error (affected phrases, entities, etc.)

#### **2. Performance Metadata**
*   **Execution Timing:** Detailed breakdown of time spent in each stage
*   **Result Metrics:** Quantifies the retrieval funnel from initial candidates to final results  
*   **Cache Efficiency:** Reports cache hit rates for performance optimization
*   **Resource Utilization:** Helps identify bottlenecks and optimization opportunities

#### **3. Error Impact Categories**

| Impact Level | Description | DialogueAgent Response Strategy |
|--------------|-------------|--------------------------------|
| `partial_results` | Some results missing but core retrieval succeeded | Acknowledge limitations: "I found relevant information about X, though some details about Y weren't available right now." |
| `degraded_quality` | Results returned but with reduced relevance/completeness | Caveat response quality: "Based on the available information, here's what I can tell you about X..." |
| `fallback_used` | System used cached or alternative data sources | Transparency: "Drawing from recent insights about X..." |

#### **4. Error Handling Integration**

The DialogueAgent's LLM receives this enhanced context and can:
*   **Acknowledge Limitations:** Gracefully handle partial failures without appearing broken
*   **Provide Transparency:** Explain when information might be incomplete
*   **Suggest Alternatives:** Redirect conversation if key information is unavailable
*   **Maintain Trust:** Show the system is working even when facing challenges

## **3. How the `DialogueAgent`'s LLM Leverages This (V9.6)**

The `DialogueAgent`'s second LLM call (the contextual response generation call) receives this comprehensive `AugmentedMemoryContext`.

**Prompt Snippet for `DialogueAgent`'s Second LLM Call (V9.6):**

```xml
<!-- ... other prompt components ... -->

<final_input_text>
  <!-- User's original message -->
</final_input_text>

<augmented_memory_context>
  <!-- The full, deterministic JSON object from HybridRetrievalTool (as defined above) -->
</augmented_memory_context>

<instructions>
You are Dot. The user previously asked about topics in `<final_input_text>`.
Based on your request for more information (you wanted to explore key phrases like those processed), the system has retrieved relevant items from the user's knowledge graph, provided in `<augmented_memory_context>`.

**Context Quality Assessment:**
- Review the `errors` array if present. Each error describes partial failures during retrieval.
- Check `performance_metadata` for result counts and timing.
- Note any `unmatched_key_phrases` that couldn't be found.

**Response Strategy Based on Context Quality:**
- If errors are present with impact "partial_results": Acknowledge what you found while noting limitations
- If errors have impact "degraded_quality": Caveat your response appropriately  
- If errors show "fallback_used": Be transparent about using alternative information sources
- If `unmatched_key_phrases` exist: Acknowledge these gaps gracefully

Your Task:
1.  **Synthesize a Response:** Review the retrieved items and any errors/limitations. Formulate a comprehensive, empathetic, and helpful `direct_response_text` that addresses the user's original query using available information while gracefully handling any gaps or limitations.
2.  **Prepare Next Turn:** Generate the `turn_context_package` including any retrieval context for future reference.

**Error Handling Examples:**
- "I found some great insights about your Project Phoenix work, though I wasn't able to access all the recent details right now. Based on what I can see..."
- "Drawing from your previous reflections on team dynamics, here's what stands out..."
- "I notice you mentioned 'that book on deep work' - I wasn't able to locate specific details about that reference, but I can share related insights from your learning journey..."

Return your entire output as a single, valid JSON object:
{
  "thought_process": "Your reasoning here, including how you handled any errors or limitations in the retrieved context.",
  "response_plan": {
    "decision": "respond_directly",
    "direct_response_text": "Your synthesized user-facing response here that gracefully handles any context limitations..."
  },
  "turn_context_package": {
    "suggested_next_focus": "...",
    "emotional_tone_to_adopt": "...",
    "flags_for_ingestion": ["..."],
    "retrieval_context": {
      "last_query_successful": true, // false if major errors occurred
      "retrieved_entity_ids": ["uuid-mu-1", "uuid-concept-A"], // Successfully retrieved IDs
      "unmatched_key_phrases": ["that book on 'deep work'"] // From context, if any
    }
  }
}
</instructions>
```

This enhanced V9.6 `AugmentedMemoryContext` provides robust error handling and performance insights while maintaining the deterministic, structured approach that enables reliable DialogueAgent responses even when facing partial system failures.

