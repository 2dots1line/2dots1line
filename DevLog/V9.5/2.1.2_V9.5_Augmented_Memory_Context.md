### **Definitive Canonical Guide: The `AugmentedMemoryContext` (V9.4 - HRT V9.3 Compatible)**

This version of `AugmentedMemoryContext` is designed to be the **direct output** of the `HybridRetrievalTool V9.3` as specified in `2.4HRTNew.md`.

#### **1. Purpose (Unchanged)**

To provide the `DialogueAgent`'s subsequent LLM call with specific, detailed, and intelligently prioritized information retrieved from the user's knowledge graph.

#### **2. Structure and JSON Template (V9.4 - Aligned with HRT V9.3 Output)**

This structure directly maps to the `Output Contract` defined in `2.4HRTNew.md` for `HybridRetrievalTool.execute()`.

```json
// Definitive Structure for AugmentedMemoryContext (V9.4)
// Output of HybridRetrievalTool V9.3
{
  "retrieved_memory_units": [ // Corresponds to HRT Output: AugmentedMemoryContext.retrievedMemoryUnits
    {
      "muid": "uuid-mu-1",
      "title": "Brainstorming Session for Project Phoenix",
      "content_snippet": "Key discussion points included timeline adjustments and resource allocation...", // HRT provides snippet
      "creation_ts": "2025-06-10T10:00:00Z",
      "source_type": "conversation_extraction",
      "importance_score": 8.5, // From MemoryUnit table
      "final_retrieval_score": 0.92, // Calculated by HRT EntityScorer
      "score_breakdown": { // Optional, if HRT's ScoringMetadata includes it
        "semantic": 0.85,
        "recency": 0.90,
        "salience": 0.95,
        "preference": 0.98
      },
      "connected_concept_ids_and_names": [
        { "id": "uuid-concept-A", "name": "Project Phoenix" },
        { "id": "uuid-concept-B", "name": "Team Bandwidth" }
      ]
      // Other fields from MemoryUnit model as needed for LLM context
    }
    // ... more MemoryUnit objects ...
  ],
  "retrieved_concepts": [ // Corresponds to HRT Output: AugmentedMemoryContext.retrievedConcepts
    {
      "id": "uuid-concept-A",
      "name": "Project Phoenix",
      "type": "project",
      "description_snippet": "A key initiative focused on developing the next-gen platform...", // HRT provides snippet
      "status": "active",
      "salience": 0.9, // From Concept table
      "final_retrieval_score": 0.95,
      "score_breakdown": { /* ... */ },
      "related_top_memory_unit_ids_and_titles": [
        { "id": "uuid-mu-1", "title": "Brainstorming Session for Project Phoenix" }
      ],
      "key_properties_values": { // HRT populates this based on schema & relevance
        "target_completion_date": "2025-12-31",
        "project_lead_name": "Sarah Adams"
      }
      // Other fields from Concept model as needed
    }
    // ... more Concept objects ...
  ],
  "retrieved_artifacts": [ // Optional, Corresponds to HRT Output: AugmentedMemoryContext.retrievedArtifacts
    {
      "id": "uuid-da-1",
      "artifact_type": "insight_summary",
      "title": "Insight: Link between Exercise and Creativity",
      "content_snippet": "Analysis shows a correlation...", // HRT provides snippet
      "created_at": "2025-06-01T15:00:00Z",
      "final_retrieval_score": 0.75,
      "score_breakdown": { /* ... */ }
      // Other fields from DerivedArtifact model as needed
    }
    // ... more DerivedArtifact objects ...
  ],
  "retrieval_summary": "Retrieved 5 relevant items (2 Memories, 3 Concepts) based on key phrases 'Project Phoenix' and 'team meeting'. Top results prioritized by recency and salience.", // Corresponds to HRT Output: AugmentedMemoryContext.retrievalSummary. This summary is generated by HRT based on its process.
  "scoring_details": { // Optional, Corresponds to HRT Output: AugmentedMemoryContext.scoringDetails
    "total_candidates_considered": 15, // From HRT
    "seed_entities_identified_from_key_phrases": 4, // Example metric HRT could provide
    "graph_traversal_depth_used": 2, // Example metric
    "weights_used": { // The actual weights used for this retrieval
      "alpha_semantic_similarity": 0.4,
      "beta_recency": 0.25,
      "gamma_salience": 0.25,
      "delta_user_preference": 0.1
    }
  },
  "unmatched_key_phrases": [ // Key phrases for which HRT found no strong initial semantic matches in Weaviate
    "that book on 'deep work'"
  ]
}
```

**Alignment with `2.4HRTNew.md`:**

*   **`retrievedMemoryUnits`, `retrievedConcepts`, `retrievedArtifacts`:** These arrays directly map to the output contract of the HRT. The HRT is responsible for fully hydrating these (fetching from PostgreSQL) *after* scoring and prioritization. The content within each object (e.g., `muid`, `title`, `content_snippet`, etc.) will be the actual data from the database for the selected top N entities.
*   **`retrievalSummary`:** This is a concise, **deterministically generated string** by the HRT. It's not an LLM summary. It could be something like: `"HRT: Processed 3 key phrases. Found 5 seed entities via Weaviate. Expanded to 15 graph candidates. Prioritized and returned top 2 MemoryUnits, 3 Concepts. Unmatched phrases: ['specific phrase']."`. This provides useful metadata to the DialogueAgent's LLM.
*   **`scoringDetails`:** This maps to `ScoringMetadata` in the HRT spec. It provides transparency into the scoring process if the `DialogueAgent`'s LLM needs to understand the weights or metrics. The `totalCandidatesEvaluated` is also explicitly mentioned.
*   **`unmatched_key_phrases`:** This field is now explicitly included, sourced from the HRT if it fails to ground certain input key phrases during its Weaviate search (Stage 2).
*   **`final_retrieval_score` and `score_breakdown`:** These are added to each retrieved entity, directly reflecting the output of the HRT's `EntityScorer` module.

**Key Clarifications for Deterministic HRT Output:**

*   **No LLM-like Summaries from HRT:** Fields like `content_summary` within `retrieved_memory_units` are now clarified as `content_snippet`. The HRT will implement a deterministic truncation or keyword-based snippet generation logic (e.g., first X characters, or sentences containing key phrases). It does **not** call an LLM to create these summaries.
*   **No `relevance_to_query_reasoning` from HRT:** The HRT does not provide natural language explanations of relevance. The relevance is implied by the `final_retrieval_score` and the fact that an item was prioritized and returned. The `DialogueAgent`'s LLM will use the provided data to infer and articulate relevance to the user.
*   **`retrieval_summary` is Factual:** This field is a factual, template-driven summary of the HRT's *actions and findings*, not a qualitative assessment of the content.

#### **3. How the `DialogueAgent`'s LLM Leverages This (V9.4)**

The `DialogueAgent`'s second LLM call (the contextual response generation call) receives this strictly deterministic `AugmentedMemoryContext`.

**Prompt Snippet for `DialogueAgent`'s Second LLM Call (V9.4):**

```xml
<!-- ... other prompt components ... -->

<final_input_text>
  <!-- User's original message -->
</final_input_text>

<augmented_memory_context>
  <!-- The full, deterministic JSON object from HybridRetrievalTool (as defined above) -->
</augmented_memory_context>

<instructions>
You are Dot. The user previously asked about topics in `<final_input_text>`.
Based on your request for more information (you wanted to explore key phrases like those in `<augmented_memory_context.retrieval_metadata.key_phrases_processed>`), the system has retrieved relevant items from the user's knowledge graph, provided in `<augmented_memory_context>`.
The `retrieval_metadata` section provides details about the search. Each retrieved item has a `final_retrieval_score`.
Note any `<unmatched_key_phrases>`.

Your Task:
1.  **Synthesize a Response:** Review the retrieved items. Formulate a comprehensive, empathetic, and helpful `direct_response_text` for the user that addresses their original query using this new information. If some key phrases were unmatched, acknowledge this gracefully.
2.  **Prepare Next Turn:** Generate the `turn_context_package`.

Return your entire output as a single, valid JSON object:
{
  "thought_process": "Your reasoning here, explaining how you used the augmented context (e.g., 'Focused on the memory unit with score 0.92 as it directly matched...').",
  "response_plan": {
    "decision": "respond_directly",
    "cypher_query": null,
    "direct_response_text": "Your synthesized user-facing response here..."
  },
  "turn_context_package": { /* ... */ }
}
</instructions>
```

