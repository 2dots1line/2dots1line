### **`2.4_V9.7_EmbeddingWorker.md`**

---

# **V9.7 Canonical Guide: `EmbeddingWorker` - Decoupled Semantic Indexing**

**Document Version:** 9.7
**Purpose:** To provide a definitive specification for the `EmbeddingWorker`, which handles all Weaviate vector indexing operations in a decoupled, resilient manner.

## **1. Core Responsibility & Philosophy**

The `EmbeddingWorker` is a **specialized asynchronous worker** responsible for **semantic indexing of knowledge entities**. Its sole purpose is to take structured knowledge created by the `IngestionAnalyst` and make it semantically searchable through vector embeddings.

**Philosophy:**
*   **Decoupled Resilience:** By separating embedding generation from knowledge creation, the system remains resilient to external API failures (Google AI, OpenAI, etc.). If the embedding service is down, knowledge is still persisted and can be indexed later.
*   **Performance Specialization:** Embedding generation can be a bottleneck. This worker can be scaled independently based on embedding workload.
*   **Single Responsibility:** Focuses solely on: text → vector → Weaviate. No other concerns.

**Location:** `workers/embedding-worker/src/EmbeddingWorker.ts`

## **2. Detailed Workflow: Processing an Embedding Job**

**Trigger:** The `IngestionAnalyst` publishes jobs to the `embedding-queue` for each new entity that needs semantic indexing.

### **Job Input Structure**

```typescript
interface EmbeddingJob {
  entityId: string;           // UUID of the MemoryUnit or Concept
  entityType: 'MemoryUnit' | 'Concept';
  textContent: string;        // The text to be embedded
  userId: string;             // For multi-tenant indexing
}
```

### **Processing Steps**

1.  **Job Pickup:** An `EmbeddingWorker` instance picks up a job from the `embedding-queue` (BullMQ).

2.  **Generate Embedding:** 
    *   Calls the atomic `TextEmbeddingTool` with the `textContent`.
    *   Receives a vector array (e.g., 1536-dimensional from OpenAI or 768-dimensional from Google).

3.  **Create/Update Weaviate Object:**
    *   Uses the Weaviate client to create or update a `UserKnowledgeItem` object.
    *   Sets the `entityId` as the object's ID for direct correlation.
    *   Stores the vector and metadata:
        ```json
        {
          "id": "muid-123",
          "properties": {
            "entityId": "muid-123",
            "entityType": "MemoryUnit",
            "userId": "user-456",
            "content": "The text content...",
            "createdAt": "2024-01-01T00:00:00Z",
            "embeddingModelVersion": "text-embedding-ada-002"
          },
          "vector": [0.1, -0.2, 0.3, ...]
        }
        ```

4.  **Error Handling:**
    *   If embedding generation fails: Retry with exponential backoff (up to 3 attempts).
    *   If Weaviate write fails: Retry with backoff.
    *   If all retries fail: Move to dead-letter queue for manual review.

5.  **Job Completion:** Mark the `embedding-queue` job as complete.

## **3. Dependencies & Tools**

| Component Name          | Type                 | Role & Responsibility                                                |
| :---------------------- | :------------------- | :------------------------------------------------------------------ |
| `TextEmbeddingTool`     | Atomic Tool          | Generates vector embeddings from text using external APIs.          |
| Weaviate Client         | Database Client      | Writes vector objects to the Weaviate instance.                     |
| `embedding-queue`       | BullMQ Queue         | Source of jobs from `IngestionAnalyst`.                             |

## **4. Configuration**

The `EmbeddingWorker` requires:

*   **Embedding Provider Config:** API keys and settings for the chosen embedding service (Google AI, OpenAI, etc.).
*   **Weaviate Connection:** Database connection details and authentication.
*   **Queue Config:** Redis connection for BullMQ.
*   **Retry Policy:** Number of attempts and backoff strategy for failed operations.

## **5. Error Resilience & Monitoring**

*   **Circuit Breaker:** If the embedding API has sustained failures, temporarily pause job processing.
*   **Metrics:** Track embedding generation latency, success/failure rates, queue depth.
*   **Alerting:** Alert on dead-letter queue accumulation or sustained API failures.

## **6. Integration Points**

**Upstream:**
*   Receives jobs from `IngestionAnalyst` via `embedding-queue`.

**Downstream:**
*   Indexed content becomes available for `HybridRetrievalTool` semantic searches.

This specialized worker ensures that semantic search capabilities remain robust and performant, while allowing the primary knowledge ingestion pipeline to operate without external API dependencies. 