### **Canonical Guide: The V8 `DialogueAgent`**

#### **1. Core Job Responsibility & Philosophy**

The `DialogueAgent` is a **stateful service that orchestrates the real-time, turn-by-turn processing of a user's conversation**. It is a deterministic software construct, not an autonomous being. Its "intelligence" emerges from its ability to meticulously prepare data for, and rigorously process the structured output from, an external Large Language Model (LLM).

**Primary Mandate:**
To receive any form of user input (text, image, audio, document), convert it to a unified textual representation, decide if its current context is sufficient to respond, orchestrate on-demand memory retrieval *if necessary*, and generate a single, coherent, context-aware response for the user while simultaneously updating its internal directive for the next turn.

**Located at:** `services/cognitive-hub/src/agents/dialogue/DialogueAgent.ts`

#### **2. Detailed Workflow: A Single Conversational Turn**

This is the strictly defined, deterministic sequence of operations executed for every user message.

**Trigger:** The `conversation.controller.ts` (refactored from `chat.controller.ts`) receives a request from `POST /api/v1/conversations/messages` and invokes the `DialogueAgent.processTurn()` method.

##### **Phase I: Input Pre-processing (Deterministic Code)**

This phase converts all user input into a single text string (`finalInputText`).

1.  **Receive Payload:** The `DialogueAgent` receives a payload containing `currentMessageText` and/or `currentMessageMedia`.
2.  **Handle Multi-Modal Input:**
    *   If `currentMessageMedia` contains an **image**, the `DialogueAgent` code calls the `vision.caption` tool.
        *   **Tool:** `VisionCaptionTool` from `packages/vision-tool/`.
        *   **Action:** It takes the image URL (e.g., from `uploads/`), calls an external vision API, and returns a descriptive text string.
    *   If `currentMessageMedia` contains an **audio file**, it calls the `audio.transcribe` tool.
        *   **Tool:** (To be created) `AudioTranscribeTool` from a new `packages/audio-tool/`.
        *   **Action:** It takes the audio file URL, calls a speech-to-text API, and returns the transcript.
    *   If `currentMessageMedia` contains a **document**, it calls the `document.extract_text` tool.
        *   **Tool:** `DocumentExtractTool` from `packages/document-tool/`.
        *   **Action:** It takes the document URL, uses a library to extract text, and returns the full text.
3.  **Assemble `finalInputText`:** The code concatenates the original `currentMessageText` with any text generated from the media tools. This `finalInputText` is now the unified input for the cognitive part of the workflow.

##### **Phase II: Context Assembly & "Router" LLM Call**

1.  **Build Initial Prompt:** The `DialogueAgent` code calls the `PromptBuilder` service.
    *   **Dependency:** `PromptBuilder.ts` (New file at `services/cognitive-hub/src/services/PromptBuilder.ts`).
    *   **Action:** The `PromptBuilder` fetches the `userMemoryProfile` from `users.memory_profile`, gets the recent conversation history from the `ConversationRepository`, and assembles the full context package.
2.  **Make "Router" LLM Call:** The `DialogueAgent` code formats a prompt for the LLM. This prompt includes the context package, the `finalInputText`, and specific instructions for the LLM to choose between two actions: `respond_directly` or `query_memory`.
    *   **Crucially, the prompt now includes instructions for `query_memory`:**
        > "If you choose `query_memory`, you must provide a list of key phrases or entity names from the user's message that you need more information about. Do not write a Cypher query. Just list the key terms.
        >
        > Return your response in this JSON format:
        > `{"decision": "query_memory", "key_phrases": ["Project Phoenix", "our conversation last week", "that feeling of creative block"], "thought_process": "The user mentioned 'Project Phoenix', which is not in my current context. I need to retrieve information about this specific entity."}`"
    *   **Dependency:** `LLMChatTool` from `packages/ai-clients/src/tools/llm-chat.tool.ts` is used to make the actual API call.

##### **Phase III: Conditional Logic & Orchestration (Deterministic Code)**

1.  **Process "Router" Response:** The `DialogueAgent` code receives and parses the structured JSON from the LLM.
2.  **Execute Logic:**
    *   **If `decision === 'respond_directly'`:** The code extracts the pre-generated response from the JSON and proceeds to Phase IV.
    *   **If `decision === 'query_memory'`:** The code extracts the `key_phrases` array. It then invokes the **On-Demand Memory Retrieval Sub-Workflow** (see Section 3) by calling the `HybridRetrievalTool` with these key phrases. The code `awaits` the final response from this sub-workflow.

##### **Phase IV: Final Response Generation & State Update**

1.  **Generate Final Response with Agent Directive:** Once a definitive `finalResponseText` has been determined (either directly or from the retrieval sub-workflow), the `DialogueAgent` code makes the final LLM call. This call is structured to generate both the user-facing response AND the agent directive for the next turn in a single operation.
    *   **Enhanced Prompt Structure:** The prompt instructs the LLM to return a structured JSON response containing both the user message and the next agent directive:
        > "Generate your response to the user and determine your directive for the next conversation turn. Return in this JSON format:
        > `{"user_response": "Your conversational response to the user here...", "next_agent_directive": "curious_explorer|supportive_companion|focused_analyst|creative_collaborator", "directive_reasoning": "Brief explanation of why this directive is appropriate for the next turn"}`"
2.  **Update Internal State:** The code parses the JSON response, extracts the `next_agent_directive`, and updates its internal `this.agentDirective` state variable.
3.  **Return Response:** The code returns the `user_response` from the JSON to the `conversation.controller.ts`.

---

#### **3. Sub-Workflow: The `HybridRetrievalTool`**

This is the detailed, corrected workflow for on-demand memory retrieval, addressing the challenge of matching fuzzy user language to the structured knowledge graph. **The LLM no longer writes Cypher.** It provides search terms, and the tool builds the queries.

**Location:** This would be a new, powerful tool, likely `HybridRetrievalTool.ts` in a new `packages/retrieval-tool/` directory.

**Trigger:** `DialogueAgent` calls `HybridRetrievalTool.execute({ keyPhrases, userId })`.

**Steps:**

**Step 1: Semantic Expansion (Weaviate)**
*   **Purpose:** To find the most relevant nodes in our knowledge graph, even if the user's phrasing doesn't exactly match the node names.
*   **Action:** The tool's code takes the list of `key_phrases` from the LLM. For each phrase, it performs a `nearText` vector search in the `UserKnowledgeItem` class in Weaviate.
*   **Dependency:** Weaviate client from `packages/database/src/weaviate/index.ts`.
*   **Output:** This search returns a list of the top N most semantically similar `UserKnowledgeItem` objects. The tool extracts their `externalId` and `entityType` (e.g., `Concept`, `MemoryUnit`). This gives us a list of "seed" entity IDs that are highly relevant to the user's query.

**Step 2: Graph Traversal (Neo4j)**
*   **Purpose:** To build context around the "seed" entities found in the previous step.
*   **Action:** The tool's code dynamically constructs a Cypher query. This query starts with the "seed" entity IDs from Step 1 and traverses the graph to find closely related nodes.
    *   `MATCH (startNode) WHERE startNode.id IN $seedIds`
    *   `MATCH p = (startNode)-[*1..2]-(relatedNode)` (find related nodes up to 2 hops away)
    *   `RETURN DISTINCT relatedNode.id as nodeId, relatedNode.type as nodeType`
*   **Dependency:** Neo4j client from `packages/database/src/neo4j/index.ts`.
*   **Output:** A new, expanded list of entity IDs, including the original seeds and their neighbors in the graph.

**Step 3: Content Hydration (PostgreSQL)**
*   **Purpose:** To fetch the actual, displayable content for all the relevant entities we've identified.
*   **Action:** The tool's code takes the final, unique list of all entity IDs gathered from Steps 1 and 2. It then performs batch `findMany` queries against the PostgreSQL database using the various repositories.
*   **Dependencies:** All repositories from `packages/database/src/repositories/` (e.g., `MemoryRepository`, `ConceptRepository`).
*   **Output:** A structured JSON object containing the full content (summaries, titles, descriptions) of all relevant `MemoryUnit`s and `Concept`s. This is the `AugmentedMemoryContext`.

**Step 4: Return to DialogueAgent**
*   **Purpose:** To provide the retrieved context back to the `DialogueAgent` for final response generation.
*   **Action:** The `HybridRetrievalTool` returns the `AugmentedMemoryContext` to the `DialogueAgent`. The `DialogueAgent` then incorporates this context into the final LLM call that generates both the user response and next agent directive. This maintains a clean separation of concerns: the tool retrieves data, the agent orchestrates the final LLM call.

---

#### **4. Dependencies & Collaborators (V8 Finalized)**

The `DialogueAgent` orchestrates a complex dance between multiple, specialized components.

| Component Name                                                      | Type     | Location                                                               | Role & Responsibility                                                                                                                   |
| :------------------------------------------------------------------ | :------- | :--------------------------------------------------------------------- | :-------------------------------------------------------------------------------------------------------------------------------------- |
| `conversation.controller`                                           | Upstream | `apps/api-gateway/src/controllers/conversation.controller.ts` (Refactored) | Invokes the agent for each user message and manages the conversation lifecycle.                                                          |
| `PromptBuilder`                                                     | Service  | `services/cognitive-hub/src/services/PromptBuilder.ts` (New)           | Assembles the multi-part context package for the LLM at the start of each turn.                                                         |
| `LLMChatTool`                                                       | Tool     | `packages/ai-clients/src/tools/llm-chat.tool.ts`                       | A low-level tool that provides a standardized interface for making API calls to the external LLM service (e.g., Google's API).          |
| **`HybridRetrievalTool`**                                           | **Tool** | **`packages/retrieval-tool/src/HybridRetrievalTool.ts` (New)**         | The critical, on-demand memory retrieval engine. Takes key phrases, queries Weaviate->Neo4j->PostgreSQL, and returns enriched context. |
| `vision.caption`, `audio.transcribe`, `document.extract_text`       | Tools    | `packages/vision-tool/`, `packages/audio-tool/`, `packages/document-tool/` | A suite of deterministic tools for pre-processing multi-modal input into a unified text format.                                         |
| `ConversationRepository`                                            | Repo     | `packages/database/src/repositories/conversation.repository.ts`        | Used by the `PromptBuilder` to fetch recent message history for the conversation context.                                               |
| `UserRepository`                                                    | Repo     | `packages/database/src/repositories/user.repository.ts`                | Used by the `PromptBuilder` to fetch the `userMemoryProfile`.                                                                           |

This detailed, canonical guide provides a clear and robust blueprint for the V8 `DialogueAgent`, fully accounting for the provided repository structure and the sophisticated, multi-database retrieval logic required.

---

#### **5. Updated Flowchart: V8 DialogueAgent Workflow**

The following flowchart accurately depicts the conditional logic, the role of the "Router" LLM call, the `HybridRetrievalTool` sub-workflow, and the consolidated final LLM call that generates both user response and agent directive.

```
                                          ┌─────────────────────────────────┐
User Message / Media Upload ─────────────>│   `conversation.controller.ts`  │
                                          │ (POST /api/v1/conversations/messages) │
                                          └───────────────┬─────────────────┘
                                                          │ 1. Invokes Agent with User Input
                                                          ▼
                                          ┌─────────────────────────────────┐
                                          │   `DialogueAgent.processTurn()`   │
                                          └───────────────┬─────────────────┘
                                                          │ 2. Pre-processes Multi-Modal Input
                                                          │ (Calls vision/audio/doc tools if needed)
                                                          │
                                                          │ 3. Assembles "Router" Prompt
                                          ┌───────────────▼───────────────┐
                                          │       `PromptBuilder`         │
                                          │ (Fetches userMemoryProfile,   │
                                          │  recent history, directives)  │
                                          └───────────────┬───────────────┘
                                                          │ 4. Makes "Router" LLM Call
                                                          ▼
                                          ┌─────────────────────────────────┐
                                          │        `llm.chat` Tool          │
                                          │ (Returns structured JSON:       │
                                          │ `{"decision": ..., "key_phrases": ...}`) │
                                          └───────────────┬─────────────────┘
                                                          │ 5. Processes Decision (Deterministic Code)
                                                          │
                  ┌───────────────────────────────────────┴───────────────────────────────────────┐
                  │                                                                               │
       IF `decision === 'query_memory'`                                                IF `decision === 'respond_directly'`
                  │                                                                               │
                  ▼                                                                               │
  ┌──────────────────────────────────────────────┐                                                │
  │     **SUB-WORKFLOW: ON-DEMAND RETRIEVAL**    │                                                │
  │                                              │                                                │
  │  6a. Calls `HybridRetrievalTool` with        │                                                │
  │      LLM-generated `key_phrases`             │                                                │
  │                 │                            │                                                │
  │      ┌──────────▼───────────┐                │                                                │
  │      │ `HybridRetrievalTool`│                │                                                │
  │      │ ┌──────────────────┐ │                │                                                │
  │      │ │   1. Weaviate    │ │──────────────┐ │                                                │
  │      │ │  (Vector Search) │ │              │ │                                                │
  │      │ └──────────────────┘ │              ▼ │                                                │
  │      │ ┌──────────────────┐ │ ┌──────────────┴──────────┐                                     │
  │      │ │    2. Neo4j      │ │ │   3. PostgreSQL         │                                     │
  │      │ │  (Graph Traversal) │ │  (Content Hydration)    │                                     │
  │      │ └──────────────────┘ │ └─────────────────────────┘                                     │
  │      └──────────┬───────────┘                │                                                │
  │                 │ 6b. Returns                │                                                │
  │                 │  `AugmentedMemoryContext`  │                                                │
  │                 ▼                            │                                                │
  │  6c. Incorporates Augmented Context          │                                                │
  │      into Final Response Generation          │                                                │
  └─────────────────┼────────────────────────────┘                                                │
                    │                                                                             │
                    ▼ 7. Prepares Final LLM Call (with or without augmented context)              │
                  ┌─────────────────────────────────┐                                             │
                  │   **FINAL LLM CALL**            │<────────────────────────────────────────────┘
                  │   Generate User Response +      │
                  │   Next Agent Directive          │
                  │   (Single JSON Response)        │
                  └───────────────┬─────────────────┘
                                  │ 8. Parses JSON response
                                  │    - Extracts `user_response`
                                  │    - Extracts `next_agent_directive`
                                  │    - Updates internal state
                                  │
                                  │ 9. Returns `user_response` to Controller
                                  ▼
                  ┌─────────────────────────────────┐
                  │   `conversation.controller.ts`  │
                  │ (Sends response back to client) │
                  └─────────────────────────────────┘